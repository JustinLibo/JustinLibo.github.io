{"meta":{"title":"HandsomeBo's Blog","subtitle":"Lnb-Tau","description":"热爱生活，分享知识","author":"Justin Bo","url":"https://github.com/JustinLibo/JustinLibo.github.io.git","root":"/JustinLibo.github.io/"},"pages":[{"title":"about","date":"2021-02-28T14:51:09.000Z","updated":"2021-02-28T14:51:47.975Z","comments":true,"path":"about/index.html","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/about/index.html","excerpt":"","text":""},{"title":"contact","date":"2021-02-28T15:21:17.000Z","updated":"2021-02-28T15:22:50.258Z","comments":true,"path":"contact/index.html","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/contact/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-02-28T14:50:57.000Z","updated":"2021-02-28T14:52:24.172Z","comments":true,"path":"tags/index.html","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2021-02-28T14:48:33.000Z","updated":"2021-02-28T14:49:18.757Z","comments":true,"path":"categories/index.html","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/index.html","excerpt":"","text":""},{"title":"friends","date":"2021-02-28T14:51:18.000Z","updated":"2021-02-28T14:52:03.238Z","comments":true,"path":"friends/index.html","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/friends/index.html","excerpt":"","text":""}],"posts":[{"title":"机器学习：聚类","slug":"机器学习---聚类","date":"2021-03-03T01:37:39.000Z","updated":"2021-03-03T02:24:13.233Z","comments":true,"path":"2021/03/03/7098.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/03/03/7098.html","excerpt":"","text":"一.无监督学习1.小例在说实战之前，我们先来简单说一说机器学习中的无监督学习。举个栗子~~ 下面是几张小狗的图片，如果我们让计算机自己把这些图片分成两类，计算机会怎么做呢？ ps：图片均来源于网络，若有侵权请联系删除，谢谢！ 因为没有明确的分类标准，所以计算机可能会按照不同的方式对这些图片进行分类，比如： 小狗是站着还是坐着 小狗脖子处是否有饰品 小狗是否露出了舌头 除此之外分类的方式还有很多，从中可以看出无监督学习的一些特点： 没有对与错（分类方式不唯一） 寻找数据的共同点从而进行分类（无论采用哪种方式进行分类，同类图片都是有共同点的） 通过这个简单的例子，下面就来看一看无监督学习的简单定义吧！ 2.简单定义无监督学习：机器学习的一种方法，没有给定事先标记过的训练示例，自动对输入的数据进行分类或分群。 3.优点： 算法不受监督信息（偏见）的约束，可能考虑到新的信息 这也就是上例所说的可以按不同方式分类，并没有一个明确的规定 不需要标签数据，极大程度扩大数据样本 无监督学习不需要标签数据，这样在面临成千上万个数据时可以让计算机自动去分类从而节省大量的人力成本。 4.主要应用：聚类分析、关联分析、维度缩减等 这里简单来谈谈聚类分析(对其他应用感兴趣的小伙伴可以自己去找一下相关资料。) 二.聚类分析1.简单定义：聚类分析又称为群分析，是根据对象某些属性的相似度，将其自动划分为不同的类别。 2.小例：例如： 一个公司可以根据自己客户几年来的数据把客户分成普通客户、vip客户、svip客户等等。这样就可以根据不同的客户类型进行不同的商业推广啦。 又比如新闻关联：给定一个关键词，可以把最近有关这个关键词的最新最热新闻推送出来。 3.常用聚类算法： KMeans聚类 根据数据与中心点距离划分类别 基于类别数据更新中心点 重复过程直到收敛 特点：实现简单、收敛快；需要指定类别数量（需要告诉计算机要分成几类） 均值漂移聚类(Meanshift) 在中心点一定区域检索数据点 更新中心 重复流程到中心点稳定 特点：自动发现类别数量，不需要人工选择；需要选择区域半径 DBSCAN算法(基于密度的空间聚类算法) 基于区域点密度筛选有效数据 基于有效数据向周边扩张，直到没有新点加入 特点：过滤噪音数据；不需要人为选择类别数量；数据密度不同时影响结果 因为后面的实战是基于KMeans算法的，所以这里详细说一下KMeans算法，想更多了解其它算法的小伙伴可以去找找相关资料。 这样可能不太好理解，下面我们来看一看它的执行流程。 假设这里把这些点分为两类，在这些点中随机选择两个聚类中心。 计算每个点到聚类中心的距离，然后将这些点进行分类。 text 更新聚类中心 重新计算每个点到聚类中心的距离并根据新的距离重新分类 直至中心不再变化为止。","categories":[{"name":"人工智能基础","slug":"人工智能基础","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"无监督学习","slug":"无监督学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"},{"name":"K-Means","slug":"K-Means","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/K-Means/"}],"author":"Justin Bo"},{"title":"机器学习联系:房价预测","slug":"机器学习联系-房价预测 - 副本 (4)","date":"2021-03-03T01:37:39.000Z","updated":"2021-03-03T01:42:05.555Z","comments":true,"path":"2021/03/03/7096.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/03/03/7096.html","excerpt":"","text":"","categories":[{"name":"人工智能基础","slug":"人工智能基础","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"author":"Justin Bo"},{"title":"机器学习之聚类—Kmeans实战","slug":"机器学习之聚类—Kmeans实战","date":"2021-03-03T01:37:39.000Z","updated":"2021-03-03T03:30:33.940Z","comments":true,"path":"2021/03/03/7095.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/03/03/7095.html","excerpt":"","text":"一.任务 采用Kmeans算法实现2D数据自动聚类，预测V1=80,V2=60的数据类别 计算预测准确率，完成结果矫正数据：data.csv 二.实战#加载数据并预览 import pandas as pd import numpy as np data = pd.read_csv('data.csv') data.head(); #定义X和y X = data.drop(['labels'],axis=1) y = data.loc[:,'labels'] y.head()#预览 pd.value_counts(y) #查看类别数(这里有0，1，2三个类别) 以及每个类别对应的样本数 #导入数据以及数据可视化 %matplotlib inline from matplotlib import pyplot as plt fig1 = plt.figure() plt.scatter(X.loc[:,'V1'],X.loc[:,'V2']) plt.title(\"un-labled data\") plt.xlabel('V1') plt.ylabel('V2') plt.show() #给出标签 fig1 = plt.figure() label0 = plt.scatter(X.loc[:,'V1'][y==0],X.loc[:,'V2'][y==0]) label1 = plt.scatter(X.loc[:,'V1'][y==1],X.loc[:,'V2'][y==1]) label2 = plt.scatter(X.loc[:,'V1'][y==2],X.loc[:,'V2'][y==2]) plt.title(\"labled data\") plt.xlabel('V1') plt.ylabel('V2') plt.legend((label0,label1,label2),('label0','label1','label2')) plt.show() #建立模型 from sklearn.cluster import KMeans KM = KMeans(n_clusters=3,random_state=0) KM.fit(X) #给出中心点centers = KM.cluster_centers_ fig3 = plt.figure() label0 = plt.scatter(X.loc[:,'V1'][y==0],X.loc[:,'V2'][y==0]) label1 = plt.scatter(X.loc[:,'V1'][y==1],X.loc[:,'V2'][y==1]) label2 = plt.scatter(X.loc[:,'V1'][y==2],X.loc[:,'V2'][y==2]) plt.title(\"labled data\") plt.xlabel('V1') plt.ylabel('V2') plt.legend((label0,label1,label2),('label0','label1','label2')) plt.scatter(centers[:,0],centers[:,1]) plt.show() #测试数据: V1=80,V2=60 y_predict_test = KM.predict([[80,60]]) print(y_predict_test) 结果表明该数据属于类别1，即上图橙色部分，但事实上我们观察80，60这个数据发现，它更接近类别2，即绿色部分，之所以出现这种错误，是因为在建立模型时我们是不知道标签的，所以就出现了标签和类别不对应的情况，这是我们需要矫正结果。 y_predict = KM.predict(X) print(pd.value_counts(y_predict),pd.value_counts(y)) 这里来对比一下预测和原有的样本对应的标签（上为预测，下为原样）可以看到1标签应该修改为2，0应该修改为1，2应该修改为0。下面我们来进行矫正~ from sklearn.metrics import accuracy_score accuracy = accuracy_score(y,y_predict) print(accuracy) 可以看到此时准确率极低 fig4 = plt.subplot(121) label0 = plt.scatter(X.loc[:,'V1'][y_predict==0],X.loc[:,'V2'][y_predict==0]) label1 = plt.scatter(X.loc[:,'V1'][y_predict==1],X.loc[:,'V2'][y_predict==1]) label2 = plt.scatter(X.loc[:,'V1'][y_predict==2],X.loc[:,'V2'][y_predict==2]) plt.title(\"predicted data\") plt.xlabel('V1') plt.ylabel('V2') plt.legend((label0,label1,label2),('label0','label1','label2')) plt.scatter(centers[:,0],centers[:,1]) fig5 = plt.subplot(122) label0 = plt.scatter(X.loc[:,'V1'][y==0],X.loc[:,'V2'][y==0]) label1 = plt.scatter(X.loc[:,'V1'][y==1],X.loc[:,'V2'][y==1]) label2 = plt.scatter(X.loc[:,'V1'][y==2],X.loc[:,'V2'][y==2]) plt.title(\"labled data\") plt.xlabel('V1') plt.ylabel('V2') plt.legend((label0,label1,label2),('label0','label1','label2')) plt.scatter(centers[:,0],centers[:,1]) plt.show() 通过图形对比可以明显看出差别 #矫正结果 y_corrected = [] for i in y_predict: if i==0: y_corrected.append(1) elif i==1: y_corrected.append(2) else: y_corrected.append(0) print(pd.value_counts(y_corrected),pd.value_counts(y)) 可以看到，结果已成功矫正 print(accuracy_score(y,y_corrected)) 准确率也非常高 y_corrected = np.array(y_corrected) print(type(y_corrected)) fig6 = plt.subplot(121) label0 = plt.scatter(X.loc[:,'V1'][y_corrected==0],X.loc[:,'V2'][y_corrected==0]) label1 = plt.scatter(X.loc[:,'V1'][y_corrected==1],X.loc[:,'V2'][y_corrected==1]) label2 = plt.scatter(X.loc[:,'V1'][y_corrected==2],X.loc[:,'V2'][y_corrected==2]) plt.title(\"corrected data\") plt.xlabel('V1') plt.ylabel('V2') plt.legend((label0,label1,label2),('label0','label1','label2')) plt.scatter(centers[:,0],centers[:,1]) fig7 = plt.subplot(122) label0 = plt.scatter(X.loc[:,'V1'][y==0],X.loc[:,'V2'][y==0]) label1 = plt.scatter(X.loc[:,'V1'][y==1],X.loc[:,'V2'][y==1]) label2 = plt.scatter(X.loc[:,'V1'][y==2],X.loc[:,'V2'][y==2]) plt.title(\"labled data\") plt.xlabel('V1') plt.ylabel('V2') plt.legend((label0,label1,label2),('label0','label1','label2')) plt.scatter(centers[:,0],centers[:,1]) plt.show() 通过图形很直观地看出无明显差别，分类也就完成了。","categories":[{"name":"人工智能基础","slug":"人工智能基础","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"K-Means","slug":"K-Means","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/K-Means/"}],"author":"Justin Bo"},{"title":"机器学习---逻辑回归:考试通过预测","slug":"机器学习---逻辑回归考试通过预测","date":"2021-03-03T01:37:39.000Z","updated":"2021-03-03T02:56:43.972Z","comments":true,"path":"2021/03/03/7094.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/03/03/7094.html","excerpt":"","text":"什么时候用逻辑回归我们想一想，当我们要解决一个分类问题，尤其是一个二分类问题时，如果我们用线性回归去解决就会面临这样一个问题：样本量变大后，准确率会下降。这时为了更好地解决这种分类问题，我们就需要采用逻辑回归的方法了。 逻辑回归方程我们先看一看逻辑回归方程 可以发现当样本值越大y越接近1，样本值越小y越接近0，以0.5为分界点就可以将y分成以下两种情况。 这时负样本就是0，正样本就是1，0和1就是我们给样本定义的标签。在考试通过问题中，可以用1代表通过（pass）,用0代表失败（failed），这样就可以通过标签0和1将失败和通过进行一个分类，就可以很好地解决二分类问题了。 当问题更复杂时，可以用g(x)代替x，然后就可以根据g(x)寻找最合适的决策边界从而解决二分类问题 比如下面这个图形： 此时虚线部分就是它的决策边界 实战任务: 基于examdata.csv数据，建立逻辑回归模型 预测Exam1 = 70, Exam2 = 60时，该同学在Exam3是 passed or failed; 建立二阶边界，提高模型准确度。 先来建立一阶边界看看准确率： #加载数据 import pandas as pd import numpy as np data = pd.read_csv('examdata.csv') data.head() #数据预览 #可视化数据 %matplotlib inline from matplotlib import pyplot as plt #导入相关包 fig1 = plt.figure() #新建一个画布 plt.scatter(data.loc[:,'Exam1'],data.loc[:,'Exam2']) #导入数据 plt.title('Exam1-Exam2') #图形名称 plt.xlabel('Exam1') #横坐标 plt.ylabel('Exam2') #纵坐标 plt.show() #展示图形 #添加标签 mask = data.loc[:,'Pass'] == 1 #如果pass等于1就是true，否则就是false print(mask)#预览 这里可以和最开始的数据预览图比较起来看，前五项Pass的值是0，0，0，1，1，所以这里前五项的结果就如下图所示了。 #将通过考试和未通过考试的用图形来区分开 fig2 = plt.figure() passed = plt.scatter(data.loc[:,'Exam1'][mask],data.loc[:,'Exam2'][mask]) failed = plt.scatter(data.loc[:,'Exam1'][~mask],data.loc[:,'Exam2'][~mask]) #这里的~mask是取反，可以理解为0 plt.title('Exam1-Exam2') plt.xlabel('Exam1') plt.ylabel('Exam2') plt.legend((passed,failed),('passed','failed')) plt.show() #将数据赋值给相关变量 x = data.drop(['Pass'],axis=1) #这里是去除pass那一列 y = data.loc[:,'Pass'] #将pass那一列的值赋给y x1 = data.loc[:,'Exam1']#将Exam1那一列的值赋给x1 x2 = data.loc[:,'Exam2']#将Exam2那一列的值赋给x2 x1.head() #这里以x1为例看一下预览效果，正确; print(x.shape,y.shape) #看一下数据维度 #建立模型以及训练模型 from sklearn.linear_model import LogisticRegression LR = LogisticRegression() LR.fit(x,y) #训练模型 这里模型已经训练好了 #预测结果 y_predict = LR.predict(x) print(y_predict) #预测结果 #评估模型表现 看一下准确率 from sklearn.metrics import accuracy_score accuracy = accuracy_score(y,y_predict) print(accuracy) 准确率达到了0.89，虽然感觉挺高的，但是判断错误的还是很多的 LR.intercept_ #截距 #θo,θ1,θ2 theta0 = LR.intercept_ theta1,theta2 = LR.coef_[0][0],LR.coef_[0][1] print(theta0,theta1,theta2) x2_new = -(theta0+theta1*x1)/theta2 print(x2_new) 求解x2_new 时可参照以下公式： fig3 = plt.figure() passed=plt.scatter(data.loc[:,'Exam1'][mask],data.loc[:,'Exam2'][mask]) failed=plt.scatter(data.loc[:,'Exam1'][~mask],data.loc[:,'Exam2'][~mask]) plt.plot(x1,x2_new) #画出决策边界 plt.title('Exam1-Exam2') plt.xlabel('Exam1') plt.ylabel('Exam2') plt.legend((passed,failed),('passed','failed')) plt.show() 然后我们来看一看建立的二阶边界函数的模型的效果 #建立一个二阶的边界 #创建新数据 x1_2 = x1*x1 x2_2 = x2*x2 x1_x2 = x1*x2 x_new = &amp;#123;'x1':x1,'x2':x2,'x1_2':x1_2,'x2_2':x2_2,'x1_x2':x1_x2&amp;#125;#将所有数据放到一个字典里面 x_new = pd.DataFrame(x_new) #方便后面进行模型数据的加载 print(x_new)#预览 #建立并训练一个新模型 LR2 = LogisticRegression() LR2.fit(x_new,y) 准确率达到了百分之百，可以看处通过二阶边界建立的模型比通过一阶边界建立的模型准确率高很多。 x1_new = x1.sort_values() #将x1_new从小到大排序 print(x1_new) #预览 这里是保证后面画图不出现交叉，使图形更好看、更直观 #θo,θ1,θ2，θ3,θ4，θ5 theta0 = LR2.intercept_ theta1,theta2,theta3,theta4,theta5 = LR2.coef_[0][0],LR2.coef_[0][1],LR2.coef_[0][2],LR2.coef_[0][3],LR2.coef_[0][4] a = theta4 b = theta5*x1_new+theta2 c = theta0+theta1*x1_new+theta3*x1_new*x1_new x2_new_boundary = (-b+np.sqrt(b*b-4*a*c))/(2*a) print(x2_new_boundary) θo,θ1,θ2,θ3,θ4,θ5的求解可以根据以下公式： 因为成绩都是正数，所以就不用图中x2那个表达式了。 fig5 = plt.figure() passed=plt.scatter(data.loc[:,'Exam1'][mask],data.loc[:,'Exam2'][mask]) failed=plt.scatter(data.loc[:,'Exam1'][~mask],data.loc[:,'Exam2'][~mask]) plt.plot(x1_new,x2_new_boundary) #画出决策边界 plt.title('Exam1-Exam2') plt.xlabel('Exam1') plt.ylabel('Exam2') plt.legend((passed,failed),('passed','failed')) plt.show()","categories":[{"name":"人工智能基础","slug":"人工智能基础","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"逻辑回归","slug":"逻辑回归","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"}],"author":"Justin Bo"},{"title":"机器学习---线性回归:房价预测","slug":"机器学习联系-房价预测","date":"2021-03-03T01:37:39.000Z","updated":"2021-03-03T02:29:11.658Z","comments":true,"path":"2021/03/03/7099.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/03/03/7099.html","excerpt":"","text":"机器学习简介小例先来简单举个例子吧！假如一家公司1月的利润为50万，然后每月增长5%，问其9月利润是多少。按照传统算法，我们知道了该公司1月的利润，知道了月增长率，就可以根据公式计算出相应的结果，而机器学习与传统算法不同的是机器学习是把月份、利润这些数据给到计算机，然后由计算机自动去求解一个函数关系进而求得结果。 传统算法：1月利润+公式→计算机→结果 机器学习：前几个月的月份+每月对应的利润→计算机→F（x）（计算机求得的函数关系）→结果 简单定义然后来看看机器学习的一个简单定义吧~ 机器学习是一种实现人工智能的方法从数据中寻找规律、建立关系，然后根据建立的关系去解决问题从数据中学习从而实现自我优化与升级 机器学习的类别1.监督学习：在已有的数据集中，训练数据包括正确结果，知道输入数据与输出结果的关系，并可以根据这种关系建立一个关系模型，在获得新数据后，就可以根据这种关系输出对应结果。 2.无监督学习：训练数据不包括正确结果，让计算机自己去数据中寻找规律。 3.半监督学习：训练数据包含少量结果，可以理解为介于监督学习和无监督学习之间。 4.强化学习：根据每次结果收获的奖惩进行学习，实现优化。就比如让机器人去做一件事，做得好就加5分，做的差就减5分，然后按照第一种方式做事获得的分比第二种方式高，那么机器人就知道第一种方式更好了。按照这种奖惩方式，程序就可以逐步寻找获得高分的方法了。 房屋预测问题实战基于usa_housing_price.csv数据，以人均收入、房屋年龄、房间数量、区域人口、房屋面积作为输入变量，来预测房屋价格。 好了话不多说，上代码！ 这里的csv文件是提前下载好的 #加载数据 import pandas as pd import numpy as np data = pd.read_csv('usa_housing_price.csv') data.head() #预览数据。数据很多，预览数据只是预览前五项。 预览结果： 再来看一下5个输入变量对应的散点图 %matplotlib inline from matplotlib import pyplot as plt #导入相关库 fig = plt.figure(figsize=(15,12)) #这里是定义画布大小 fig1 =plt.subplot(231) #231是指两行三列的第一个图，下面的232是指两行三列的第二个图，依次类推 plt.scatter(data.loc[:,'Avg. Area Income'],data.loc[:,'Price']) #获取数据，画出一个散点图 plt.title('Price VS Income') #散点图的名称 fig2 =plt.subplot(232) plt.scatter(data.loc[:,'Avg. Area House Age'],data.loc[:,'Price']) plt.title('Price VS House Age') fig3 =plt.subplot(233) plt.scatter(data.loc[:,'Avg. Area Number of Rooms'],data.loc[:,'Price']) plt.title('Price VS Number of Rooms') fig4 =plt.subplot(234) plt.scatter(data.loc[:,'Area Population'],data.loc[:,'Price']) plt.title('Price VS Area Population') fig5 =plt.subplot(235) plt.scatter(data.loc[:,'size'],data.loc[:,'Price']) plt.title('Price VS size') plt.show() #展示散点图 注意左上角的1e6是代表10的6次方，即2.5所代表值是2500000。 #定义输入变量X_multi X_multi = data.drop(['Price'],axis=1) #去掉price所在列，因为有5个输入变量，输出结果只有1个，所以去掉price y = data.loc[:,'Price'] X_multi 预览 可以看到这些数据是5000行5列的 from sklearn.linear_model import LinearRegression #导入相关库 LR_multi = LinearRegression()#建立模型 LR_multi.fit(X_multi,y) #训练模型 这里模型已经训练好了： #模型预测 y_predict_multi = LR_multi.predict(X_multi) print(y_predict_multi) 预测结果： #模型评估 from sklearn.metrics import mean_squared_error,r2_score mean_squared_error_multi = mean_squared_error(y,y_predict_multi) r2_score_multi = r2_score(y,y_predict_multi) print(mean_squared_error_multi,r2_score_multi) 评估结果： r2越接近1越好，这里达到0.91，模型还算不错 #图形评估 fig6 = plt.figure(figsize=(9,6)) plt.scatter(y,y_predict_multi) 这里y值和y的预测值接近一条45度的直线，可以看出差别不大 X_test = [66000,3,6,20000,150] X_test = np.array(X_test).reshape(1,-1) #将输入数据转化为数组 print(X_test) y_test_predict = LR_multi.predict(X_test) print(y_test_predict) 自己输入一组数据，可以看到预测结果为114万多一点","categories":[{"name":"人工智能基础","slug":"人工智能基础","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"线性回归","slug":"线性回归","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"}],"author":"Justin Bo"},{"title":"机器学习联系:房价预测","slug":"机器学习联系-房价预测 - 副本 (5)","date":"2021-03-03T01:37:39.000Z","updated":"2021-03-03T01:42:05.555Z","comments":true,"path":"2021/03/03/7097.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/03/03/7097.html","excerpt":"","text":"","categories":[{"name":"人工智能基础","slug":"人工智能基础","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"author":"Justin Bo"},{"title":"JupyterNotebook的优化与配置","slug":"JupyterNotebook的优化与配置","date":"2021-03-01T14:06:37.000Z","updated":"2021-03-03T01:37:07.772Z","comments":true,"path":"2021/03/01/18760.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/03/01/18760.html","excerpt":"","text":"Jupyter Notebook使用在新建环境中安装Jupyter Notebook 打开Anacanda prompt,键入canda activate envy_name，进入新建环境键入pip install Jupyter Notebook。 建议先将pip升级为最新版本：pip install --upgrade pip。 也可在Anacanda中直接安装不过没有命令行观察直接。Jupyter Notebook的界面优化 安装jupyter-themes包 https://github.com/dunovank/jupyter-themes 在Anacanda prompt中键入使用清华源下载速度会快很多。 pip install --upgrade jupyterthemes -i https://pypi.tuna.tsinghua.edu.cn/simple/ 在安装过程中出现ERROR: Cannot uninstall [pacakage]. It is a distutils installed project…类似错误，就可以先使用pip install --ignore-installed [package]后，再装。也可在E:\\APP\\A\\Lib\\site-packages安装目录下删除所有带有**[pacakage]**的模块。 设置jupyter notebook样式 安装成功后可以先运行 jt -h 查看帮助文档推荐设置的样式代码为 jt -t grade3 -f fira -fs 16 -cellw 90% -ofs 11 -dfs 11 -T 在Jupyter Notebook中显示汉字在绘制散点图时，无法正常显示汉字插入如下两行代码即可解决： plt.rcParams['font.sans-serif'] = ['SimHei'] plt.rcParams['axes.unicode_minus'] = False 若出现以下错误==用来正常显示中文标签显示错误代码plt.rcParams[‘font.sans-serif’] = [‘SimHei’]无法运行==则有以下解决方法： 1. 下载simhei.ttf字体，这里提供一个链接SimHei.ttf 2. 找到你的解释器的fonts文件夹下的ttf文件夹，例如我的解释器是Anaconda，在Anaconda的安装目录下，fonts文件夹的位置如上图的路径：D:\\AnaInstallDir\\Anaconda3\\Lib\\site-packages\\ matplotlib\\mpl-data\\fonts\\ttf。 若解释器是自己安装的Python，文件夹的位置一般为： C:\\Users\\用户名\\AppData\\Local\\Programs\\ Python\\ Python35\\Lib\\site-packages\\matplotlib\\mpl-data\\fonts\\ttf 3. 将下载的SimHei.ttf文件放入ttf文件夹下再运行程序就OK啦（即代码plt.rcParams[‘font.sans-serif’] = [‘SimHei’]可以运行） 参考链接：https://blog.csdn.net/xcjjenifer/article/details/105419979 运行效果如下：","categories":[{"name":"人工智能基础","slug":"人工智能基础","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Anaconda","slug":"Anaconda","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/Anaconda/"}],"author":"Justin Bo"},{"title":"Hello World","slug":"hello-world","date":"2021-02-25T13:13:51.582Z","updated":"2021-02-28T15:48:33.708Z","comments":true,"path":"2021/02/25/16107.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/02/25/16107.html","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new \"My New Post\" More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"Anaconda","slug":"Anaconda","date":"2021-01-04T10:18:11.000Z","updated":"2021-03-01T14:01:43.511Z","comments":true,"path":"2021/01/04/41489.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/01/04/41489.html","excerpt":"","text":"1.为什么要使用虚拟环境假如当前我们有多个项目A、B、C等等，这些项目中某些项目都需要使用一个相同的库，但是需要的版本却不一样，而这时不管哪个项目使用的都是默认的Python环境，对于这些项目我们只能运行其中一个，如果需要运行另外的项目，必须安装与之相匹配的版本的库。这时我们就可以创建一些完全独立的局部Python环境来实现一个项目使用一个“环境”，这个项目需要安装什么库，只需去其对应的环境中安装即可，这样项目之间就不会互相干扰了，项目的管理也会变得非常方便。 2.conda创建虚拟环境在创建虚拟环境前，需要先下载Anaconda。下载好以后，可以打开命令行输入conda -V检验conda是否安装成功以及当前安装的conda的版本信息。 创建虚拟环境：打开命令行，使用conda create -n env_name python=x.x(这里输入你想要的版本，如3.5、3.6等)命令创建环境名为env_name的虚拟环境。（出现下图所示时输入y即可 创建好虚拟环境以后使用conda activate env_name（创建时的环境名）命令激活虚拟环境（注意:这是Windows下的激活命令）。激活后就可以使用pip install xxx（包名）命令在该虚拟环境下安装你需要的包了。安装好以后，可以使用conda list命令查看已安装的包的信息。若想要退出虚拟环境，输入conda deactivate即可（同样也是Windows下的命令）。存在的虚拟环境可以在Anaconda安装目录里的envs文件下找到，也可以在命令行使用conda env list 或 conda info -e命令查看。 删除虚拟环境及虚拟环境中的某个包 删除虚拟环境:conda remove -n env_name --all 删除虚拟环境中的某个包:conda remove --name env_name package_name 3.pip换源因为我们获取的包，默认是直接从pypi官网获取的，而pypi是国外的，所以网速很慢，这时我们换成国内镜像源就可以大大提高安装速度了。 这里是几个国内源阿里云 http://mirrors.aliyun.com/pypi/simple/ 中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/ 豆瓣(douban) http://pypi.douban.com/simple/ 清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/ 中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/ 这里以清华源为例。 临时换源:在安装命令后加上-i,指定一个pip源,。eg: pip install scrapy -i https://pypi.tuna.tsinghua.edu.cn/simple 永久换源:win+R 打开用户目录%HOMEPATH%，在此目录下创建 pip 文件夹，在 pip 目录下创建 pip.ini 文件, 内容如下: [global] timeout = 6000 index-url = https://pypi.tuna.tsinghua.edu.cn/simple trusted-host = pypi.tuna.tsinghua.edu.cn","categories":[{"name":"人工智能学习","slug":"人工智能学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Anaconda","slug":"Anaconda","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/Anaconda/"}],"author":"Justin Bo"},{"title":"人工智能与机器学习概念、应用、实现方法","slug":"人工智能与机器学习概念、应用、实现方法","date":"2021-01-03T00:42:01.000Z","updated":"2021-03-03T01:33:55.856Z","comments":true,"path":"2021/01/03/25359.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/01/03/25359.html","excerpt":"","text":"人工智能概念、应用、实现方法生活案例出发：身边的人工智能 人脸识别、自动驾驶、医疗图片诊断 智能机器人、AlphaGo 多语言翻译、智能客服、情感分类 ​ 核心概念人工智能—维基百科定义 人工智能，亦称智机器智能，指由人制造出来的机器所表现出来的智能。 人工智能的核心问题包括建构能够跟人类似甚至超卓的推理、知识、规划、学习、交流、感知、移物、使用工具和操控机械的能力等 人工智能—核心关键词 Intelligence:“The capacity to learn and solve problems ” (自主学习及解决问题的能力) Artificial Intelligence: The simulation of human intelligence by machines (机器对人类智能的模仿) 人工智能—核心定义人工智能就其本质而言，是机器对人的思维或行为过程的模拟，让它能像人一样思考或行动 从过去的信息中寻找规律（经验），将规律或经验吸收，并为未来的判断或决策提供依据。 核心点：学习、优化、决策 部分应用场景 AI安防：利用计算机视觉技术和大数据分析犯罪嫌疑人生活轨迹及可能出现的场所 AI金融：利用复杂的 AI 系统能极其迅速的做出交易决策。 AI工业制造：机器人代替工人在危险场所完成工作 ,在流水线上高效完成重复工作 人工智能发展阶段通用人工智能（“强”人工智能）：具备与人类同等智慧、或超越人类的人工智能，能表现正常人类所具有的所有智能行为。 目前AI技术无法达到通用人工智能 无法判断离通用人工智能还有多远 非通用人工智能（“弱”人工智能）：不需要具有人类完整的认知能力，甚至是完全不具有人类所拥有的感官认知能力 可处理特定问题，在特定应用中很厉害 目前AI处于此阶段 人工智能实现方法：符号人工智能&amp;机器学习（Symbolic Artificial Intelligence &amp; Machine learning)符号学习基于逻辑与规则的学习方法，用一些特定的符号来表示现实的事物或者观念(符号 不局限于图像文字，还包括了既定的逻辑、规则等） ➢ 根据既定的逻辑和顺序告诉机器 接下来做什么 ➢ 遵循if…then…原则 𝑎 = 10, 𝑏 = 20 𝑐 = 𝑎 + 𝑏, 𝑖𝑓 𝑎 &gt; 𝑏； 𝑐 =𝑎 − 𝑏, 𝑖𝑓 𝑎 &lt; 𝑏 𝑐 = ? ? **需要先知道或假设信息的逻辑、规律 ** 机器学习从数据中自动分析获得规律，并利用规律对未知数据进行预测或用于解决实际问题的方法。 ➢从数据中学习规律，实现对原有推 理的更新，实现“自我优化” ➢ 现阶段主流的AI学习算法 只要将数据给机器，机器会自动寻找a b c之间的关系。 机器学习与深度学习的关系机器学习是一种实现人工智能的方法， 深度学习是一种实现机器学习的技术。机器学习：从数据中自动分析获得规律，并利 用规律对未知数据进行预测或用于解决实际问 题的方法。 深度学习：机器在对数据进行分析时，将引入 类人类神经结构模型，实现对复杂数据的理解 与推理，通常可应用于更为复杂的任务中。机器学习概念、应用、实现方法 现实问题思考：营业额预测店铺A第一周营业额为5000，每周增长10%，第10周是多少？ 现实问题思考—自动图像分类目标：以下六组图片，按照自己喜爱的方式分成两组 分组一：站着或非站着 分组二：白色或黄色 分组三：吐舌头或不吐舌头 机器学习应用与概念机器学习是一种实现人工智能的方法。 从数据中寻找规律、建立关系，根据建立的关系去解决问题。 机器学习应用场景 数据挖掘 无人驾驶 机器视觉 语言理解 实现人工智能的主流方法！ 四大学习方法• 监督学习 （Supervised Learning）:在分类过程中，如果所有训练数据都有标签，则为有监督学习，用于分类或者回归。 • 无监督学习（Unsupervised Learning）:如果数据没有标签，显然就是无监督学习了，也即聚类（clustering）。 • 半监督学习 (Semi-supervised Learning) :其训练数据的一部分是有标签的，另一部分没有标签，而没标签数据的数量常常远远大于有标签数据数量（这也是符合现实情况的）。隐藏在半监督学习下的基本规律在于：数据的分布必然不是完全随机的，通过一些有标签数据的局部特征，以及更多没标签数据的整体分布，就可以得到可以接受甚至是非常好的分类结果。 • 强化学习 (Reinforcement Learning) :强化学习是针对你再次没有标注数据集的情况而言的，但你还是有办法来区分是否越来越接近目标（回报函数（reward function））。经典的儿童游戏——“hotter or colder”。（Huckle Buckle Beanstalk的一个变体）是这个概念的一个很好的例证。你的任务是找到一个隐藏的目标物件，然后你的朋友会喊出你是否越来越hotter（更接近）或colder（远离）目标物件。“Hotter/colder”就是回报函数，而算法的目标就是最大化回报函数。你可以把回报函数当做是一种延迟和稀疏的标签数据形式：而不是在每个数据点中获得特定的“right/wrong”答案，你会得到一个延迟的反应，而它只会提示你是否在朝着目标方向前进。 四大学习方法应用场景","categories":[{"name":"人工智能基础","slug":"人工智能基础","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"author":"Justin Bo"},{"title":"数据库三范式","slug":"数据库三范式","date":"2020-03-02T03:45:00.000Z","updated":"2021-03-02T10:01:52.909Z","comments":true,"path":"2020/03/02/15177.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2020/03/02/15177.html","excerpt":"","text":"参考 https://blog.csdn.net/dh2442897094/article/details/105656952https://blog.csdn.net/qq_42351920/article/details/81303550 数据库设计三大范式为了建立冗余较小、结构合理的数据库，设计数据库时必须遵循一定的规则。在关系型数据库中这种规则就称为范式。范式是符合某一种设计要求的总结。要想设计一个结构合理的关系型数据库，必须满足一定的范式。 第一范式(确保每列保持原子性)； 第二范式(确保表中的每列都和主键相关)； 第三范式(确保每列都和主键列直接相关,而不是间接相关)； 在实际开发中最为常见的设计范式有三个： 第一范式（1NF）：要求数据库表的每一列都是不可分割的原子数据项。第一范式是最基本的范式。如果数据库表中的所有字段值都是不可分解的原子值，就说明该数据库表满足了第一范式。 第一范式的合理遵循需要根据系统的实际需求来定。比如某些数据库系统中需要用到“地址”这个属性，本来直接将“地址”属性设计成一个数据库表的字段就行。但是如果系统经常会访问“地址”属性中的“城市”部分，那么就非要将“地址”这个属性重新拆分为省份、城市、详细地址等多个部分进行存储，这样在对地址中某一部分操作的时候将非常方便。这样设计才算满足了数据库的第一范式，如下表所示。举例说明：在上面的表中，“家庭信息”和“学校信息”列均不满足原子性的要求，故不满足第一范式，调整如下：可见，调整后的每一列都是不可再分的，因此满足第一范式（1NF）； 第二范式（2NF）： 第二范式需要确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。 在1NF的基础上，非码属性必须完全依赖于候选码（在1NF基础上消除非主属性对主码的部分函数依赖）。也就是说在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。举例说明：在上图所示的情况中，同一个订单中可能包含不同的产品，因此主键必须是“订单号”和“产品号”联合组成，但可以发现，产品数量、产品折扣、产品价格与“订单号”和“产品号”都相关，但是订单金额和订单时间仅与“订单号”相关，与“产品号”无关，这样就不满足第二范式的要求，调整如下，需分成两个表： 第三范式（3NF）： 第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。 在2NF基础上，任何非主属性不依赖于其它非主属性（在2NF基础上消除传递依赖） 举例说明： 上表中，所有属性都完全依赖于学号，所以满足第二范式，但是“班主任性别”和“班主任年龄”直接依赖的是“班主任姓名”， 而不是主键“学号”，所以需做如下调整： 这样以来，就满足了第三范式的要求。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"author":"Justin Bo"},{"title":"如何用Hexo优雅的书写文章","slug":"写文章","date":"2020-01-03T00:09:10.000Z","updated":"2021-03-01T09:58:07.954Z","comments":true,"path":"2020/01/03/62216.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2020/01/03/62216.html","excerpt":"","text":"了解文章目录所有的文章都是放在主目录下source文件下的_posts目录下的，这里参考我的存放目录E:\\mblog\\source\\_posts 这里作出两点说明： 该目录下可以再创建目录，系统可以识别到多层文件夹中的文章，方便分类 如果用命令生成的新文章一定是在_posts主目录下 熟悉操作指令其实就是一句话，再把生成的文章拖到_posts目录下你自己创建的文件夹即可，文件后缀为.md hexo n 你的文章名 Tips： 如果嫌麻烦，复制md文件再粘贴也是个好办法 开始书写文章写MarkDown这里推荐Typora，非常好用，点开创建的文件，先看看里面有啥\\---title: typora-vue-theme主题介绍date: 2018-09-07 09:25:00\\--- 两个虚线之间的内容就是叫Front-matter，主要是你文章的配置，具体配置如下，这里不同主题不一样，我以Matery主题为例 Front-matter 选项中的所有内容均为非必填的。但我仍然建议至少填写 title 和 date 的值。 配置选项 默认值 描述 title Markdown 的文件标题 文章标题，强烈建议填写此选项 date 文件创建时的日期时间 发布时间，强烈建议填写此选项，且最好保证全局唯一 author 根 _config.yml 中的 author 文章作者 img featureImages 中的某个值 文章特征图，推荐使用图床(腾讯云、七牛云、又拍云等)来做图片的路径.如: http://xxx.com/xxx.jpg top true 推荐文章（文章是否置顶），如果 top 值为 true，则会作为首页推荐文章 cover false v1.0.2版本新增，表示该文章是否需要加入到首页轮播封面中 coverImg 无 v1.0.2版本新增，表示该文章在首页轮播封面需要显示的图片路径，如果没有，则默认使用文章的特色图片 password 无 文章阅读密码，如果要对文章设置阅读验证密码的话，就可以设置 password 的值，该值必须是用 SHA256 加密后的密码，防止被他人识破。前提是在主题的 config.yml 中激活了 verifyPassword 选项 toc true 是否开启 TOC，可以针对某篇文章单独关闭 TOC 的功能。前提是在主题的 config.yml 中激活了 toc 选项 mathjax false 是否开启数学公式支持 ，本文章是否开启 mathjax，且需要在主题的 _config.yml 文件中也需要开启才行 summary 无 文章摘要，自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要 categories 无 文章分类，本主题的分类表示宏观上大的分类，只建议一篇文章一个分类 tags 无 文章标签，一篇文章可以多个标签 keywords 文章标题 文章关键字，SEO 时需要 reprintPolicy cc_by 文章转载规则， 可以是 cc_by, cc_by_nd, cc_by_sa, cc_by_nc, cc_by_nc_nd, cc_by_nc_sa, cc0, noreprint 或 pay 中的一个 注意: 1.如果 img 属性不填写的话，文章特色图会根据文章标题的 hashcode 的值取余，然后选取主题中对应的特色图片，从而达到让所有文章都的特色图各有特色。 2.date 的值尽量保证每篇文章是唯一的，因为本主题中 Gitalk 和 Gitment 识别 id 是通过 date 的值来作为唯一标识的。 3.如果要对文章设置阅读验证密码的功能，不仅要在 Front-matter 中设置采用了 SHA256 加密的 password 的值，还需要在主题的 _config.yml 中激活了配置。有些在线的 SHA256 加密的地址，可供你使用：开源中国在线工具、chahuo、站长工具。 4.您可以在文章md文件的 front-matter 中指定 reprintPolicy 来给单个文章配置转载规则 以下为文章的 Front-matter 示例。 最全示例 title: typora-vue-theme主题介绍 date: 2018-09-07 09:25:00 author: 赵奇 img: /source/images/xxx.jpg top: true cover: true coverImg: /images/1.jpg password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92 toc: false mathjax: false summary: 这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要 categories: Markdown tags: - Typora - Markdown Tips：你会发现一个问题，每次hexo n的时候Front-matter中内容少的可怜，那怎么修改默认的格式呢？只要去主目录下找到scaffolds文件夹下找到一个post.md文件修改即可 首行缩进方法 由于markdowm会自动限定格式，所以缩进显得比较困难，通常我们使用Tab按键或者打空格实现的缩进都只能缩进一小部分，这时可以通过占位符实现更多的缩进效果，使得文章变得美观 一个汉字占两个空格大小，所以使用四个空格就可以达到首行缩进两个汉字的效果。有如下几种方法： 一个空格大小的表示： 或 ，此时只要在相应需要缩进的段落前加上 4个 如上的标记即可，注意要带上分号 两个空格的大小表示： 或 ，同理，使用2个即可缩进2个汉字，推荐使用该方式。 不换行空格： 或 ，使用4个 即可。 范例不使用任何缩进效果 使用Tab实现缩进 在前面打上很多空格实现缩进 使用4个 &amp;#160 实现缩进 使用2个 &amp;emsp 实现缩进 使用 4个&amp;ensp 实现缩进","categories":[{"name":"工具","slug":"工具","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/hexo/"}],"author":"JustinBo"},{"title":"hexo搭建博客步骤","slug":"博客搭建","date":"2020-01-01T03:19:08.000Z","updated":"2021-03-02T07:31:16.604Z","comments":true,"path":"2020/01/01/63100.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2020/01/01/63100.html","excerpt":"","text":"hexo简介hexo 自称为：快速、简洁且高效的博客框架。 笔者用起来确实还可以，大概介绍下几个特性： 提供了不同的layout，可将文章存为草稿，需要时publish即可； 可维护全局的数据，在source/_data文件夹下添加yaml文件，通过site.data获取； 可指定文件的特有变量，通过Front-matter实现； 支持模板，在scaffolds文件夹下可自定义模板，并进行发布； 支持标签插件，可以在文章文件中使用标签%%来插入特定内容； 提供命令行操作，如：hexo init初始化项目、hexo new新建文章、hexo pulish发布草稿文件、hexo generate生成静态文件、hexo server启动服务器； hexo搭建博客步骤 前提是必须安装好git和nodejs； 执行 “npm install -g hexo-cli”，安装好hexo； 选定文件夹，通过 “hexo init $folder” 初始化一个名为 $folder 的文件夹； cd $folder, 再执行npm install，至此hexo的博客框架已经搭建完成！ 完成上述步骤后，可执行hexo server, 访问http://localhost:4000, 会发现一个HelloWorld页面已经可以访问！ 选用volantis主题 设置项目使用的主题: 项目根目录下的_config.yml文件中设置 theme: volantis; 如果Hexo版本在5.0.2及以上，可以直接通过npm i hexo-theme-volantis进行安装；笔者为了项目的可读性，采用了源代码拷贝到theme文件夹的方案（记得删除.git文件夹,否则git提交时会出问题!） 按照依赖的插件：npm i hexo-generator-search hexo-generator-json-content(站内搜索)，npm i hexo-renderer-stylus（Stylus 渲染器） 完成上述步骤后执行hexo server, 访问http://localhost:4000, 是不是发现端庄不失典雅的博客网站已经完成了！ 尝试新建文章执行 hexo new post $newPostName，会在_post文件夹下新建一个名为$newPostName的md文件，一个新的文章便建立完成。 这时你只需要关注你的博文输出即可啦！ 发布至GitHub Pages如果你期望能通过GitHub Pages来访问你的博客网站，做如下几步： 通过GitHub新建一个repository，名为：&lt;你的 GitHub 用户名&gt;.github.io； 本地检出该repository； 在博客源码的项目中执行命令：hexo generate –deploy，会生成public文件夹，该文件夹里便是博客所有的静态页面文件； 将public文件夹中的文件全部拷贝到新建repository的master分支下； 将master文件推送至远程master分支即可！ 静待一会，访问：http://&lt;你的 GitHub 用户名&gt;.github.io便能访问你自定义的博客了！ 如果你有自己的域名，可以在域名解析配置成 记录类型：CNAME，记录值：&lt;你的 GitHub 用户名&gt;.github.io。 注意了！！！ 此时还需要在GitHub Page项目中根目录下加上名为CNAME的文件，文件内容为你自己的域名。 正如你看到的，搭建一个个人博客网站就是如此便捷！","categories":[{"name":"工具","slug":"工具","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/hexo/"}],"author":"Justin Bo"},{"title":"花津南路(完....)","slug":"花津南路","date":"2019-05-31T10:21:19.000Z","updated":"2021-03-03T01:14:13.621Z","comments":true,"path":"2019/05/31/7103.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2019/05/31/7103.html","excerpt":"","text":"序 不知道什么时候的事情了, 对拍好看的照片总是有点向往 有台相机还是蛮好的 , 有空的时候也有动力跑出去瞎拍一通 不是配置狗 , 相机 Sony Nex 5T , 16-50 mm ,f3.5-5.6 , 七工匠 25mm f1.8 后期用的是LightRoom (瞎调) 2019-06-11 镜湖 中江桥 噪点奇多 看来是时候入手一个大光圈镜头了 Others 2019-06-16 学校的荷花 2019-06-21 八佰伴附近 AHNU赭山校区 夜晚的镜湖 2019-06-26 滨江公园 长江二桥 长江江景 世茂滨江 天主教堂 Others","categories":[{"name":"旅行志","slug":"旅行志","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E6%97%85%E8%A1%8C%E5%BF%97/"}],"tags":[{"name":"旅行","slug":"旅行","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%97%85%E8%A1%8C/"},{"name":"摄影","slug":"摄影","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%91%84%E5%BD%B1/"}],"author":"Justin Bo"}],"categories":[{"name":"人工智能基础","slug":"人工智能基础","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"},{"name":"人工智能学习","slug":"人工智能学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E4%B9%A0/"},{"name":"数据库","slug":"数据库","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"工具","slug":"工具","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E5%B7%A5%E5%85%B7/"},{"name":"旅行志","slug":"旅行志","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E6%97%85%E8%A1%8C%E5%BF%97/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"无监督学习","slug":"无监督学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"},{"name":"K-Means","slug":"K-Means","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/K-Means/"},{"name":"逻辑回归","slug":"逻辑回归","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"},{"name":"线性回归","slug":"线性回归","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},{"name":"Anaconda","slug":"Anaconda","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/Anaconda/"},{"name":"数据库","slug":"数据库","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"hexo","slug":"hexo","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/hexo/"},{"name":"旅行","slug":"旅行","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%97%85%E8%A1%8C/"},{"name":"摄影","slug":"摄影","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%91%84%E5%BD%B1/"}]}