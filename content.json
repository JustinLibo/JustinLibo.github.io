{"meta":{"title":"HandsomeBo's Blog","subtitle":"Lnb-Tau","description":"热爱生活，分享知识","author":"Justin Bo","url":"https://github.com/JustinLibo/JustinLibo.github.io.git","root":"/JustinLibo.github.io/"},"pages":[{"title":"categories","date":"2021-02-28T14:48:33.000Z","updated":"2021-02-28T14:49:18.757Z","comments":true,"path":"categories/index.html","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2021-02-28T14:51:09.000Z","updated":"2021-02-28T14:51:47.975Z","comments":true,"path":"about/index.html","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/about/index.html","excerpt":"","text":""},{"title":"contact","date":"2021-02-28T15:21:17.000Z","updated":"2021-02-28T15:22:50.258Z","comments":true,"path":"contact/index.html","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/contact/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-02-28T14:50:57.000Z","updated":"2021-02-28T14:52:24.172Z","comments":true,"path":"tags/index.html","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/index.html","excerpt":"","text":""},{"title":"friends","date":"2021-02-28T14:51:18.000Z","updated":"2021-02-28T14:52:03.238Z","comments":true,"path":"friends/index.html","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/friends/index.html","excerpt":"","text":""}],"posts":[{"title":"浏览器打开网页","slug":"浏览器访问网页","date":"2021-03-11T09:21:56.000Z","updated":"2021-03-11T09:44:05.359Z","comments":true,"path":"2021/03/11/48570.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/03/11/48570.html","excerpt":"","text":"当浏览器地址栏输入一个url网址后，敲下回车会发生什么？ 1.利用DNS域名解析系统进行域名解析，将域名解析成IP因为域名只是一个别名，计算机只认识IP，所以需要DNS解析一下（如果有端口号需要识别端口号，否则进入默认端口：http协议默认端口号是80，https默认端口号是443） 2.查找ip对应的主机服务器如果是第一次访问该服务器，会向网络供应商（移动、联通…）请求 3.TCP的三次握手，经过三次在客户端和服务器之间传递报文，建立连接 4.发起http请求，请求入口文件，后端接收到请求相关信息，返回入口文件 5.解析入口文件，同时如果有资源请求继续发送http请求… 6.过程中如果碰到css文件，js文件，需要去加载外部文件 加载css，渲染html结构 加载js 执行js的逻辑，有ajax请求，在此去服务器请求数据 通过数据刷新DOM 7.文件渲染完成（TCP的四次挥手，断开连接） 访问网页过程","categories":[{"name":"面试常见问题","slug":"面试常见问题","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E9%9D%A2%E8%AF%95%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E7%BD%91%E7%BB%9C/"}],"author":"Justin Bo"},{"title":"CNN实现猫狗图像分类","slug":"CNN实现猫狗图像分类","date":"2021-02-20T01:37:39.000Z","updated":"2021-03-04T02:33:44.670Z","comments":true,"path":"2021/02/20/7097.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/02/20/7097.html","excerpt":"","text":"前文中已经对CNN做了详细的介绍，下面开始实战： 实战一： 基于dataset\\training_set数据，根据提供的结构，建立CNN模型，识别图片中的猫/狗，计算预测准确率： 1.识别图片中的猫/狗、计算dataset\\test_set测试数据预测准确率 2.从网站下载猫/狗图片，对其进行预测 #load the data from keras.preprocessing.image import ImageDataGenerator#图片加载 train_datagen = ImageDataGenerator(rescale=1./255)#图片预处理 #加载出图片 training_set = train_datagen.flow_from_directory('./dataset/training_set',target_size=(50,50),batch_size=32,class_mode='binary') #路径 像素大小（50,50） 每次选择32张图片 模式选择二分类binary #set up the cnn model from keras.models import Sequential from keras.layers import Conv2D, MaxPool2D, Flatten, Dense#卷积层 池化层 图像的展开 model = Sequential() #卷积层 model.add(Conv2D(32,(3,3),input_shape=(50,50,3),activation='relu'))#32个3×3 #池化层 model.add(MaxPool2D(pool_size=(2,2)))#2×2 移动窗口是1 #卷积层 model.add(Conv2D(32,(3,3),activation='relu')) #池化层 model.add(MaxPool2D(pool_size=(2,2))) #flattening layer model.add(Flatten())#转化成展开 #FC layer model.add(Dense(units=128,activation='relu'))#隐藏层 model.add(Dense(units=1,activation='sigmoid'))#输出层 #configure the model model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy']) model.summary()#模型结构 #train the model model.fit_generator(training_set,epochs=20)#迭代20次 #accuracy on the training data accuracy_train = model.evaluate_generator(training_set)#计算准确率 print(accuracy_train) #accuracy on the test data test_set = train_datagen.flow_from_directory('./dataset/test_set',target_size=(50,50),batch_size=32,class_mode='binary') accuracy_test = model.evaluate_generator(test_set) print(accuracy_test) 训练准确率为100%测试准确率为76%，对于二分类50%的准确率来说，此模型的还是可以来进行使用的 #load single image from keras.preprocessing.image import load_img, img_to_array pic_dog = 'dog.jpg' pic_dog = load_img(pic_dog,target_size=(50,50)) pic_dog = img_to_array(pic_dog) pic_dog = pic_dog/255 pic_dog = pic_dog.reshape(1,50,50,3) result = model.predict_classes(pic_dog) print(result) [[1]]代表预测的是小狗 pic_cat = 'cat1.jpg' pic_cat = load_img(pic_cat,target_size=(50,50)) pic_cat = img_to_array(pic_cat) pic_cat = pic_cat/255 pic_cat = pic_cat.reshape(1,50,50,3) result = model.predict_classes(pic_cat) print(result) [[0]]代表预测的是小猫 training_set.class_indices {‘cats’: 0, ‘dogs’: 1} # make prediction on multiple images import matplotlib as mlp font2 = &amp;#123;'family' : 'SimHei', 'weight' : 'normal', 'size' : 20, &amp;#125; mlp.rcParams['font.family'] = 'SimHei' mlp.rcParams['axes.unicode_minus'] = False from matplotlib import pyplot as plt from matplotlib.image import imread from keras.preprocessing.image import load_img from keras.preprocessing.image import img_to_array from keras.models import load_model a = [i for i in range(1,10)] fig = plt.figure(figsize=(10,10)) for i in a: img_name = str(i)+'.jpg' img_ori = load_img(img_name, target_size=(50, 50)) img = img_to_array(img_ori) img = img.astype('float32')/255 img = img.reshape(1,50,50,3) result = model.predict_classes(img) img_ori = load_img(img_name, target_size=(250, 250)) plt.subplot(3,3,i) plt.imshow(img_ori) plt.title('预测为：狗狗' if result[0][0] == 1 else '预测为：猫咪') plt.show() 从上述结果来看，只有最中间的一幅小猫的图片被预测成小狗的错误，其他预测都是准确的。 实战二： 使用VGG16的结构提取图像特征，再根据特征建立mlp模型，实现猫狗图像识别。训练/测试数据：dataset\\data_vgg： 1.对数据进行分离、计算测试数据预测准确率 2.从网站下载猫/狗图片，对其进行预测 mlp模型一个隐藏层，10个神经元 #load the data from keras.preprocessing.image import load_img,img_to_array img_path = '1.jpg' img = load_img(img_path,target_size=(224,224))#希望加载进来的像素大小是224*224 img = img_to_array(img) type(img) from keras.applications.vgg16 import VGG16 from keras.applications.vgg16 import preprocess_input import numpy as np model_vgg = VGG16(weights='imagenet',include_top=False)#去掉全连接层 x = np.expand_dims(img,axis=0) x = preprocess_input(x)#可以把图片矩阵转化成可用于VGG16输入的矩阵 #特征提取 features = model_vgg.predict(x) #flatten features = features.reshape(1,7*7*512) #visualize the data %matplotlib inline from matplotlib import pyplot as plt fig = plt.figure(figsize=(5,5)) img = load_img(img_path,target_size=(224,224)) plt.imshow(img) #load image and preprocess it with vgg16 structure from keras.preprocessing.image import img_to_array,load_img from keras.applications.vgg16 import VGG16 from keras.applications.vgg16 import preprocess_input import numpy as np model_vgg = VGG16(weights='imagenet', include_top=False) #define a method to load and preprocess the image def modelProcess(img_path,model): img = load_img(img_path, target_size=(224, 224)) img = img_to_array(img) x = np.expand_dims(img,axis=0) x = preprocess_input(x) x_vgg = model.predict(x) x_vgg = x_vgg.reshape(1,25088) return x_vgg #list file names of the training datasets import os folder = \"dataset/data_vgg/cats\" dirs = os.listdir(folder) #generate path for the images img_path = [] for i in dirs: if os.path.splitext(i)[1] == \".jpg\": img_path.append(i) img_path = [folder+\"//\"+i for i in img_path] #preprocess multiple images features1 = np.zeros([len(img_path),25088]) for i in range(len(img_path)): feature_i = modelProcess(img_path[i],model_vgg) print('preprocessed:',img_path[i]) features1[i] = feature_i folder = \"dataset/data_vgg/dogs\" dirs = os.listdir(folder) img_path = [] for i in dirs: if os.path.splitext(i)[1] == \".jpg\": img_path.append(i) img_path = [folder+\"//\"+i for i in img_path] features2 = np.zeros([len(img_path),25088]) for i in range(len(img_path)): feature_i = modelProcess(img_path[i],model_vgg) print('preprocessed:',img_path[i]) features2[i] = feature_i #label the results print(features1.shape,features2.shape) y1 = np.zeros(300) y2 = np.ones(300) #generate the training data X = np.concatenate((features1,features2),axis=0) y = np.concatenate((y1,y2),axis=0) y = y.reshape(-1,1) #split the training and test data from sklearn.model_selection import train_test_split X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=50) #set up the mlp model from keras.models import Sequential from keras.layers import Dense model = Sequential() model.add(Dense(units=10,activation='relu',input_dim=25088)) model.add(Dense(units=1,activation='sigmoid')) model.summary() #configure the model model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy']) #train the model model.fit(X_train,y_train,epochs=50) from sklearn.metrics import accuracy_score y_train_predict = model.predict_classes(X_train) accuracy_train = accuracy_score(y_train,y_train_predict) print(accuracy_train) #测试准确率 y_test_predict = model.predict_classes(X_test) accuracy_test = accuracy_score(y_test,y_test_predict) print(accuracy_test) 训练准确率为98.57%测试准确率为97.78%，两者准确率都是非常高的，而且要比实战一中的模型预测要更加准。 img_path = 'myself_cat.jpg' img = load_img(img_path,target_size=(224,224)) img = img_to_array(img) x = np.expand_dims(img,axis=0) x = preprocess_input(x) features = model_vgg.predict(x) features = features.reshape(1,7*7*512) result = model.predict_classes(features) print(result) [[0]] 可以看出预测的结果是正确的 # coding:utf-8 import matplotlib as mlp font2 = &amp;#123;'family' : 'SimHei', 'weight' : 'normal', 'size' : 20, &amp;#125; mlp.rcParams['font.family'] = 'SimHei' mlp.rcParams['axes.unicode_minus'] = False from matplotlib import pyplot as plt from matplotlib.image import imread from keras.preprocessing.image import load_img from keras.preprocessing.image import img_to_array from keras.models import load_model #from cv2 import load_img a = [i for i in range(1,10)] fig = plt.figure(figsize=(10,10)) for i in a: img_name = str(i)+'.jpg' img_path = img_name img = load_img(img_path, target_size=(224, 224)) img = img_to_array(img) x = np.expand_dims(img,axis=0) x = preprocess_input(x) x_vgg = model_vgg.predict(x) x_vgg = x_vgg.reshape(1,25088) result = model.predict_classes(x_vgg) img_ori = load_img(img_name, target_size=(250, 250)) plt.subplot(3,3,i) plt.imshow(img_ori) plt.title('预测为：狗狗' if result[0][0] == 1 else '预测为：猫咪') plt.show() 效果还可以","categories":[{"name":"人工智能基础","slug":"人工智能基础","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"深度学习","slug":"深度学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"CNN","slug":"CNN","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/CNN/"}],"author":"Justin Bo"},{"title":"深度学习之卷积神经网络","slug":"深度学习之卷积神经网络","date":"2021-02-15T01:37:39.000Z","updated":"2021-03-04T01:26:57.011Z","comments":true,"path":"2021/02/15/7097.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/02/15/7097.html","excerpt":"","text":"推荐阅读： https://www.sohu.com/a/241338315_787107 文章把VGG16写的相当通俗易懂。 图像卷积运算对图像矩阵与滤波器矩阵进行对应相乘再求和运算，转化得到新的矩阵。作用:快速定位图像中某些边缘特征英文: convolutionCNNA与B的卷积通常表示为:A*B或convolution(A,B)···· X11 X12 X13A= X21 X22 X23···· X31 X32 X33····F= W11 W12···· W21 W22 包含竖向轮廓的区域非常亮(灰度值越大月亮） 计算机根据样本图片，自动寻找合适的轮廓过滤器，对新图片进行轮廓匹配 池化:按照一个固定规则对图像矩阵进行处理，将其转换为更低维度的矩阵 最大法池化(Max-pooling) Stride为窗口滑动步长，用于池化、卷积的计算中。 保留核心信息的情况下，实现维度缩减 把卷积、池化、mlp先后连接在一起，组成卷积神经网络。 作用: 1、使部分神经元为0，防止过拟合 2、助于模型的求解 Relu函数:f(x) = max(x, 0) 转化成全连接层 卷积神经网络两大特点： **参数共享(parameter sharing):**同一个特征过滤器可用于整张图片 **稀疏连接(sparsity of connections):**生成的特征图片每个节点只与原图片中特定节点连接 ？×？=（n-f+1）×(n-f+1) 卷积运算导致的两个问题: 图像被压缩，造成信息丢失 边缘信息使用少，容易被忽略 图像填充(padding) 通过在图像各边增加像素，使其在进行卷积运算后维持原图大小 通过padding增加像素的数量，由过滤器尺寸与stride决定 经典的CNN模型1、参考经典的CNN结构搭建新模型 2、使用经典的CNN模型结构对图像预处理，再建立MLP模型 经典的CNN模型: LeNet-5 （1）6个5×5的过滤器滑动窗口为1（2）平均值池化：2×2的滑动窗口是2（3）16个5×5的过滤器滑动窗口为1（4）池化：2×2的滑动窗口是2（5）展开（6）进行MLP模型（7）输出10个类别输入图像:32 X 32灰度图，1个通道(channel)训练参数:约60,000个特点:1、随着网络越深，图像的高度和宽度在缩小，通道数在增加2、卷积与池化先后成对使用 AlexNet （1）96个11×11的过滤器滑动窗口为4 （2）最大值池化：3×3的滑动窗口是2 （3）256个5×5的过滤器滑动窗口为1 （4）最大值池化：3×3的滑动窗口是2 … （n）输出1000个类别输入图像:227X 227X 3 RGB图，3个通道训练参数:约60,000,000个特点:1、适用于识别较为复杂的彩色图，可识别1000种类别2、结构比LeNet更为复杂，使用Relu作为激活函数学术界开始相信深度学习技术,在计算机视觉应用中可以得到很不错的结果。 VGG 所有的卷积都是64个3×3的过滤器移动窗口是1，最大值池化：2×2的滑动窗口是2不断重复同样的步骤输入图像: 227 X 227X 3 RGB图，3个通道训练参数:约138,000,000个特点:1、所有卷积层filter 宽和高都是3，步长为1,padding 都使用same convolution;2、所有池化层的 filter 宽和高都是2，步长都是2;3、相比alexnet，有更多的filter用于提取轮廓信息，具有更高精准性 经典的CNN模型用于新场景1、使用经典的CNN模型结构对图像预处理，再建立MLP模型;（1）加载经典的CNN模型，剥除其FC层，对图像进行预处理（2）把预处理完成的数据作为输入，分类结果为输出，建立一个mlp模型（3）模型训练2、参考经典的CNN结构搭建新模型","categories":[{"name":"人工智能基础","slug":"人工智能基础","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"深度学习","slug":"深度学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"CNN","slug":"CNN","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/CNN/"}],"author":"Justin Bo"},{"title":"MLP实现图像多分类","slug":"MLP实现图像多分类","date":"2021-02-11T01:37:39.000Z","updated":"2021-03-04T01:26:37.965Z","comments":true,"path":"2021/02/11/7096.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/02/11/7096.html","excerpt":"","text":"多层感知器（MLP）问题引入：（1）根据检测数据x1、x2及其标签，判断x1=0.7、x2=0.6时所属类别 如果采用逻辑回归，因为边界函数并不是单一的直线或圆之类的函数，所以这个逻辑回归边界函数不很好找到，如果初始数据属性有100项甚至更多项，那么形成的多项式数据量会非常庞大。 （2）根据各个国家100项指标，判断其未来5年的发展潜力 这样的数据有多个指标，那么其二次多项式个数就会更加多。 (3）自动识别图片中的动物是猫还是狗。 计算机对于图片看到的是一个二维数组的数值，其中有图像RGB值，灰度值，像素值三种。具体关系见链接图像RGB值灰度值像素值三者关系 上图就为计算机所看到的图片值 计算机的解决办法： 随机选取固定的两个点P1,P2，基于其灰度值进行分类预测。 红色点是小猫，蓝色点是小狗，由此可以进行逻辑回归进行分类。 对于输入的数据矩阵如下 可以看出，输入的数据量非常巨大，再加上模型的二次项，就超过了百亿，非常耗时耗空间 由此产生多层感知器（Multi-Layer Percepron） 多层感知器的介绍多层感知机（MLP，Multilayer Perceptron）也叫人工神经网络（ANN，Artificial Neural Network），之所以叫做人工神经网络，原因如下： 可以尝试建立一个模型，其结构模仿人的思考机制 上图为神经元结构，按照此结构进行简化成为我们想要的模型结构 上图为逻辑回归模型的框架，由此可以看出两种模型的框架结构非常像。 根据这种模型框架我们做出了如下的多层感知器模型框架 其中a1 a2 …an等等隐含神经元都是通过输入神经元x1 x2 …xn直接的关系得出的，以此同样的方法影响后面的隐含神经元，最后再影响输出神经元。y=g(z)=1/(1+exp(-z))a21=g(θ110 x0+θ111 x1+θ112 x2+…)a22=g(θ210 x0+θ211 x1+θ212 x2+…)… 隐藏层：多层感知机在单层神经网络的基础上引入了一到多个**隐藏层(hidden layer)**。 隐藏层位于输入层和输出层之间。上图展示了一个多层感知机的神经网络，它含有一个隐藏层，该层中有5个隐藏单元。输入和输出个数为别为4和3，中间隐藏层中包含了5个隐藏单元。由于输入层不涉及计算，多层感知机的层数为2。隐藏层中的神经元和输入层各输入完全连接，输出层中的神经元和隐藏层中的各神经元也完全连接。因此多层感知机中的隐藏层和输出层都是全连接。激活函数：使用隐藏变量使用按照元素运算的非线性函数进行变换，然后作为一个全连接层的输入。这个非线性函数进行转换叫作激活函数(activation function)这里只介绍一下sigmoid函数sigmoid函数可以将元素的值转变到0和1之间sigmoid(x)=g(x)=1/(1+exp(-x)) MLP用于非线性分类预测要求：在不增加高次项数据的情况下，如何通过MLP实现非线性分类预测 通过这三个逻辑回归模型组合在一起形成多层感知器 多分类： 将数据分为两种以上的类别 将下列图片分成小猫、小狗和小马三类 最后的结果1 0 0就代表是小猫，0 1 0就代表的是小狗 ，0 0 1就代表的是小马。 Keras介绍Keras是一个用Python编写的用于神经网络开发的应用接口，调用开接口可以实现神经网络、卷积神经网络、循环神经网络等常用深度学习算法的开发特点:集成了深度学习中各类成熟的算法，容易安装和使用，样例丰富，教程和文档也非常详细；能够以TensorFlow,或者Theano作为后端运行。Keras or TensorflowTensorflow是一个采用数据流图，用于数值计算的开源软件库，可自动计算模型相关的微分导数:非常适合用于神经网络模型的求解。Keras可看作为tensorflow封装后的一个接口(Keras作为前端，TensorFlow作为后端。Keras为用户提供了一个易于交互的外壳)方便进行深度学习的快速开发。 实战部分基于mnist数据集，建立mlp模型，实现0-9数字的十分类： 实现mnist数据载入，可视化图形数字 完成数据预处理：图像数据维度转换与归一化、输出结果格式转换 计算模型在预测数据集的准确率 模型结构：两层隐藏层，每层有392个神经元 首先显示一张3*3的图片 #load the mnist data from keras.datasets import mnist (X_train,y_train),(X_test,y_test)=mnist.load_data() #visualize the data img1=X_train[0] from matplotlib import pyplot as plt fig1=plt.figure(figsize=(3,3)) plt.imshow(img1) plt.title(y_train[0]) plt.show() #format the input data 将28列28行转化为784组数据 feature_size=img1.shape[0]*img1.shape[1] X_train_format = X_train.reshape(X_train.shape[0],feature_size) X_test_format = X_test.reshape(X_test.shape[0],feature_size) print(X_train_format.shape) 60000个样本，每个样本784列数据 #normalize the input data 归一化，将原本用于描述像素点的rgb值转化为0到1的值 X_train_normal = X_train_format/255 X_test_normal = X_test_format/255 #format the output data(labels) from keras.utils import to_categorical y_train_format = to_categorical(y_train) y_test_format = to_categorical(y_test) print(y_train_format[0])#原本是5，现在是第5个元素为1,索引从0开始 原本维度为784，因为隐藏层为俩层所以每层设置392个单元 #set up the model from keras.models import Sequential from keras.layers import Dense,Activation mlp=Sequential() mlp.add(Dense(units=392,activation='sigmoid',input_dim=feature_size)) mlp.add(Dense(units=392,activation='sigmoid')) mlp.add(Dense(units=10,activation='softmax')) mlp.summary() #configure the model mlp.compile(loss='categorical_crossentropy',optimizer='adam') #categorical_crossentropy多分类函数 #train the model mlp.fit(X_train_normal,y_train_format,epochs=10)#训练10次 #评估模型 y_train_predict=mlp.predict_classes(X_train_normal) from sklearn.metrics import accuracy_score accuracy_train= accuracy_score(y_train,y_train_predict) print(accuracy_train) 训练的准确率非常高 y_test_predict=mlp.predict_classes(X_test_normal) accuracy_test= accuracy_score(y_test,y_test_predict) print(accuracy_test) 测试的准确率也非常高 接下来对数据进行随机展示，这里随机选择了第9001个 img2 = X_test[9000] fig2 = plt.figure(figsize = (3,3)) #imshow画矩阵 plt.imshow(img2) plt.title(y_test_prdict[9000]) plt.show() 预测成功！！！","categories":[{"name":"人工智能基础","slug":"人工智能基础","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"深度学习","slug":"深度学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"多层感知机","slug":"多层感知机","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"}],"author":"Justin Bo"},{"title":"机器学习---逻辑回归:考试通过预测","slug":"机器学习---逻辑回归考试通过预测","date":"2021-02-08T01:37:39.000Z","updated":"2021-03-04T01:26:07.563Z","comments":true,"path":"2021/02/08/7094.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/02/08/7094.html","excerpt":"","text":"什么时候用逻辑回归我们想一想，当我们要解决一个分类问题，尤其是一个二分类问题时，如果我们用线性回归去解决就会面临这样一个问题：样本量变大后，准确率会下降。这时为了更好地解决这种分类问题，我们就需要采用逻辑回归的方法了。 逻辑回归方程我们先看一看逻辑回归方程 可以发现当样本值越大y越接近1，样本值越小y越接近0，以0.5为分界点就可以将y分成以下两种情况。 这时负样本就是0，正样本就是1，0和1就是我们给样本定义的标签。在考试通过问题中，可以用1代表通过（pass）,用0代表失败（failed），这样就可以通过标签0和1将失败和通过进行一个分类，就可以很好地解决二分类问题了。 当问题更复杂时，可以用g(x)代替x，然后就可以根据g(x)寻找最合适的决策边界从而解决二分类问题 比如下面这个图形： 此时虚线部分就是它的决策边界 实战任务: 基于examdata.csv数据，建立逻辑回归模型 预测Exam1 = 70, Exam2 = 60时，该同学在Exam3是 passed or failed; 建立二阶边界，提高模型准确度。 先来建立一阶边界看看准确率： #加载数据 import pandas as pd import numpy as np data = pd.read_csv('examdata.csv') data.head() #数据预览 #可视化数据 %matplotlib inline from matplotlib import pyplot as plt #导入相关包 fig1 = plt.figure() #新建一个画布 plt.scatter(data.loc[:,'Exam1'],data.loc[:,'Exam2']) #导入数据 plt.title('Exam1-Exam2') #图形名称 plt.xlabel('Exam1') #横坐标 plt.ylabel('Exam2') #纵坐标 plt.show() #展示图形 #添加标签 mask = data.loc[:,'Pass'] == 1 #如果pass等于1就是true，否则就是false print(mask)#预览 这里可以和最开始的数据预览图比较起来看，前五项Pass的值是0，0，0，1，1，所以这里前五项的结果就如下图所示了。 #将通过考试和未通过考试的用图形来区分开 fig2 = plt.figure() passed = plt.scatter(data.loc[:,'Exam1'][mask],data.loc[:,'Exam2'][mask]) failed = plt.scatter(data.loc[:,'Exam1'][~mask],data.loc[:,'Exam2'][~mask]) #这里的~mask是取反，可以理解为0 plt.title('Exam1-Exam2') plt.xlabel('Exam1') plt.ylabel('Exam2') plt.legend((passed,failed),('passed','failed')) plt.show() #将数据赋值给相关变量 x = data.drop(['Pass'],axis=1) #这里是去除pass那一列 y = data.loc[:,'Pass'] #将pass那一列的值赋给y x1 = data.loc[:,'Exam1']#将Exam1那一列的值赋给x1 x2 = data.loc[:,'Exam2']#将Exam2那一列的值赋给x2 x1.head() #这里以x1为例看一下预览效果，正确; print(x.shape,y.shape) #看一下数据维度 #建立模型以及训练模型 from sklearn.linear_model import LogisticRegression LR = LogisticRegression() LR.fit(x,y) #训练模型 这里模型已经训练好了 #预测结果 y_predict = LR.predict(x) print(y_predict) #预测结果 #评估模型表现 看一下准确率 from sklearn.metrics import accuracy_score accuracy = accuracy_score(y,y_predict) print(accuracy) 准确率达到了0.89，虽然感觉挺高的，但是判断错误的还是很多的 LR.intercept_ #截距 #θo,θ1,θ2 theta0 = LR.intercept_ theta1,theta2 = LR.coef_[0][0],LR.coef_[0][1] print(theta0,theta1,theta2) x2_new = -(theta0+theta1*x1)/theta2 print(x2_new) 求解x2_new 时可参照以下公式： fig3 = plt.figure() passed=plt.scatter(data.loc[:,'Exam1'][mask],data.loc[:,'Exam2'][mask]) failed=plt.scatter(data.loc[:,'Exam1'][~mask],data.loc[:,'Exam2'][~mask]) plt.plot(x1,x2_new) #画出决策边界 plt.title('Exam1-Exam2') plt.xlabel('Exam1') plt.ylabel('Exam2') plt.legend((passed,failed),('passed','failed')) plt.show() 然后我们来看一看建立的二阶边界函数的模型的效果 #建立一个二阶的边界 #创建新数据 x1_2 = x1*x1 x2_2 = x2*x2 x1_x2 = x1*x2 x_new = &amp;#123;'x1':x1,'x2':x2,'x1_2':x1_2,'x2_2':x2_2,'x1_x2':x1_x2&amp;#125;#将所有数据放到一个字典里面 x_new = pd.DataFrame(x_new) #方便后面进行模型数据的加载 print(x_new)#预览 #建立并训练一个新模型 LR2 = LogisticRegression() LR2.fit(x_new,y) 准确率达到了百分之百，可以看处通过二阶边界建立的模型比通过一阶边界建立的模型准确率高很多。 x1_new = x1.sort_values() #将x1_new从小到大排序 print(x1_new) #预览 这里是保证后面画图不出现交叉，使图形更好看、更直观 #θo,θ1,θ2，θ3,θ4，θ5 theta0 = LR2.intercept_ theta1,theta2,theta3,theta4,theta5 = LR2.coef_[0][0],LR2.coef_[0][1],LR2.coef_[0][2],LR2.coef_[0][3],LR2.coef_[0][4] a = theta4 b = theta5*x1_new+theta2 c = theta0+theta1*x1_new+theta3*x1_new*x1_new x2_new_boundary = (-b+np.sqrt(b*b-4*a*c))/(2*a) print(x2_new_boundary) θo,θ1,θ2,θ3,θ4,θ5的求解可以根据以下公式： 因为成绩都是正数，所以就不用图中x2那个表达式了。 fig5 = plt.figure() passed=plt.scatter(data.loc[:,'Exam1'][mask],data.loc[:,'Exam2'][mask]) failed=plt.scatter(data.loc[:,'Exam1'][~mask],data.loc[:,'Exam2'][~mask]) plt.plot(x1_new,x2_new_boundary) #画出决策边界 plt.title('Exam1-Exam2') plt.xlabel('Exam1') plt.ylabel('Exam2') plt.legend((passed,failed),('passed','failed')) plt.show()","categories":[{"name":"人工智能基础","slug":"人工智能基础","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"逻辑回归","slug":"逻辑回归","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"}],"author":"Justin Bo"},{"title":"机器学习：聚类","slug":"机器学习---聚类","date":"2021-02-05T01:37:39.000Z","updated":"2021-03-04T01:25:11.109Z","comments":true,"path":"2021/02/05/7098.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/02/05/7098.html","excerpt":"","text":"一.无监督学习1.小例在说实战之前，我们先来简单说一说机器学习中的无监督学习。举个栗子~~ 下面是几张小狗的图片，如果我们让计算机自己把这些图片分成两类，计算机会怎么做呢？ ps：图片均来源于网络，若有侵权请联系删除，谢谢！ 因为没有明确的分类标准，所以计算机可能会按照不同的方式对这些图片进行分类，比如： 小狗是站着还是坐着 小狗脖子处是否有饰品 小狗是否露出了舌头 除此之外分类的方式还有很多，从中可以看出无监督学习的一些特点： 没有对与错（分类方式不唯一） 寻找数据的共同点从而进行分类（无论采用哪种方式进行分类，同类图片都是有共同点的） 通过这个简单的例子，下面就来看一看无监督学习的简单定义吧！ 2.简单定义无监督学习：机器学习的一种方法，没有给定事先标记过的训练示例，自动对输入的数据进行分类或分群。 3.优点： 算法不受监督信息（偏见）的约束，可能考虑到新的信息 这也就是上例所说的可以按不同方式分类，并没有一个明确的规定 不需要标签数据，极大程度扩大数据样本 无监督学习不需要标签数据，这样在面临成千上万个数据时可以让计算机自动去分类从而节省大量的人力成本。 4.主要应用：聚类分析、关联分析、维度缩减等 这里简单来谈谈聚类分析(对其他应用感兴趣的小伙伴可以自己去找一下相关资料。) 二.聚类分析1.简单定义：聚类分析又称为群分析，是根据对象某些属性的相似度，将其自动划分为不同的类别。 2.小例：例如： 一个公司可以根据自己客户几年来的数据把客户分成普通客户、vip客户、svip客户等等。这样就可以根据不同的客户类型进行不同的商业推广啦。 又比如新闻关联：给定一个关键词，可以把最近有关这个关键词的最新最热新闻推送出来。 3.常用聚类算法： KMeans聚类 根据数据与中心点距离划分类别 基于类别数据更新中心点 重复过程直到收敛 特点：实现简单、收敛快；需要指定类别数量（需要告诉计算机要分成几类） 均值漂移聚类(Meanshift) 在中心点一定区域检索数据点 更新中心 重复流程到中心点稳定 特点：自动发现类别数量，不需要人工选择；需要选择区域半径 DBSCAN算法(基于密度的空间聚类算法) 基于区域点密度筛选有效数据 基于有效数据向周边扩张，直到没有新点加入 特点：过滤噪音数据；不需要人为选择类别数量；数据密度不同时影响结果 因为后面的实战是基于KMeans算法的，所以这里详细说一下KMeans算法，想更多了解其它算法的小伙伴可以去找找相关资料。 这样可能不太好理解，下面我们来看一看它的执行流程。 假设这里把这些点分为两类，在这些点中随机选择两个聚类中心。 计算每个点到聚类中心的距离，然后将这些点进行分类。 text 更新聚类中心 重新计算每个点到聚类中心的距离并根据新的距离重新分类 直至中心不再变化为止。","categories":[{"name":"人工智能基础","slug":"人工智能基础","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"无监督学习","slug":"无监督学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"},{"name":"K-Means","slug":"K-Means","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/K-Means/"}],"author":"Justin Bo"},{"title":"机器学习之聚类—Kmeans实战","slug":"机器学习之聚类—Kmeans实战","date":"2021-02-05T01:37:39.000Z","updated":"2021-03-04T02:31:24.101Z","comments":true,"path":"2021/02/05/7095.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/02/05/7095.html","excerpt":"","text":"一.任务 采用Kmeans算法实现2D数据自动聚类，预测V1=80,V2=60的数据类别 计算预测准确率，完成结果矫正数据：data.csv 二.实战#加载数据并预览 import pandas as pd import numpy as np data = pd.read_csv('data.csv') data.head(); #定义X和y X = data.drop(['labels'],axis=1) y = data.loc[:,'labels'] y.head()#预览 pd.value_counts(y) #查看类别数(这里有0，1，2三个类别) 以及每个类别对应的样本数 #导入数据以及数据可视化 %matplotlib inline from matplotlib import pyplot as plt fig1 = plt.figure() plt.scatter(X.loc[:,'V1'],X.loc[:,'V2']) plt.title(\"un-labled data\") plt.xlabel('V1') plt.ylabel('V2') plt.show() #给出标签 fig1 = plt.figure() label0 = plt.scatter(X.loc[:,'V1'][y==0],X.loc[:,'V2'][y==0]) label1 = plt.scatter(X.loc[:,'V1'][y==1],X.loc[:,'V2'][y==1]) label2 = plt.scatter(X.loc[:,'V1'][y==2],X.loc[:,'V2'][y==2]) plt.title(\"labled data\") plt.xlabel('V1') plt.ylabel('V2') plt.legend((label0,label1,label2),('label0','label1','label2')) plt.show() #建立模型 from sklearn.cluster import KMeans KM = KMeans(n_clusters=3,random_state=0) KM.fit(X) #给出中心点centers = KM.cluster_centers_ fig3 = plt.figure() label0 = plt.scatter(X.loc[:,'V1'][y==0],X.loc[:,'V2'][y==0]) label1 = plt.scatter(X.loc[:,'V1'][y==1],X.loc[:,'V2'][y==1]) label2 = plt.scatter(X.loc[:,'V1'][y==2],X.loc[:,'V2'][y==2]) plt.title(\"labled data\") plt.xlabel('V1') plt.ylabel('V2') plt.legend((label0,label1,label2),('label0','label1','label2')) plt.scatter(centers[:,0],centers[:,1]) plt.show() #测试数据: V1=80,V2=60 y_predict_test = KM.predict([[80,60]]) print(y_predict_test) 结果表明该数据属于类别1，即上图橙色部分，但事实上我们观察80，60这个数据发现，它更接近类别2，即绿色部分，之所以出现这种错误，是因为在建立模型时我们是不知道标签的，所以就出现了标签和类别不对应的情况，这是我们需要矫正结果。 y_predict = KM.predict(X) print(pd.value_counts(y_predict),pd.value_counts(y)) 这里来对比一下预测和原有的样本对应的标签（上为预测，下为原样）可以看到1标签应该修改为2，0应该修改为1，2应该修改为0。下面我们来进行矫正~ from sklearn.metrics import accuracy_score accuracy = accuracy_score(y,y_predict) print(accuracy) 可以看到此时准确率极低 fig4 = plt.subplot(121) label0 = plt.scatter(X.loc[:,'V1'][y_predict==0],X.loc[:,'V2'][y_predict==0]) label1 = plt.scatter(X.loc[:,'V1'][y_predict==1],X.loc[:,'V2'][y_predict==1]) label2 = plt.scatter(X.loc[:,'V1'][y_predict==2],X.loc[:,'V2'][y_predict==2]) plt.title(\"predicted data\") plt.xlabel('V1') plt.ylabel('V2') plt.legend((label0,label1,label2),('label0','label1','label2')) plt.scatter(centers[:,0],centers[:,1]) fig5 = plt.subplot(122) label0 = plt.scatter(X.loc[:,'V1'][y==0],X.loc[:,'V2'][y==0]) label1 = plt.scatter(X.loc[:,'V1'][y==1],X.loc[:,'V2'][y==1]) label2 = plt.scatter(X.loc[:,'V1'][y==2],X.loc[:,'V2'][y==2]) plt.title(\"labled data\") plt.xlabel('V1') plt.ylabel('V2') plt.legend((label0,label1,label2),('label0','label1','label2')) plt.scatter(centers[:,0],centers[:,1]) plt.show() 通过图形对比可以明显看出差别 #矫正结果 y_corrected = [] for i in y_predict: if i==0: y_corrected.append(1) elif i==1: y_corrected.append(2) else: y_corrected.append(0) print(pd.value_counts(y_corrected),pd.value_counts(y)) 可以看到，结果已成功矫正 print(accuracy_score(y,y_corrected)) 准确率也非常高 y_corrected = np.array(y_corrected) print(type(y_corrected)) fig6 = plt.subplot(121) label0 = plt.scatter(X.loc[:,'V1'][y_corrected==0],X.loc[:,'V2'][y_corrected==0]) label1 = plt.scatter(X.loc[:,'V1'][y_corrected==1],X.loc[:,'V2'][y_corrected==1]) label2 = plt.scatter(X.loc[:,'V1'][y_corrected==2],X.loc[:,'V2'][y_corrected==2]) plt.title(\"corrected data\") plt.xlabel('V1') plt.ylabel('V2') plt.legend((label0,label1,label2),('label0','label1','label2')) plt.scatter(centers[:,0],centers[:,1]) fig7 = plt.subplot(122) label0 = plt.scatter(X.loc[:,'V1'][y==0],X.loc[:,'V2'][y==0]) label1 = plt.scatter(X.loc[:,'V1'][y==1],X.loc[:,'V2'][y==1]) label2 = plt.scatter(X.loc[:,'V1'][y==2],X.loc[:,'V2'][y==2]) plt.title(\"labled data\") plt.xlabel('V1') plt.ylabel('V2') plt.legend((label0,label1,label2),('label0','label1','label2')) plt.scatter(centers[:,0],centers[:,1]) plt.show() 通过图形很直观地看出无明显差别，分类也就完成了。","categories":[{"name":"人工智能基础","slug":"人工智能基础","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"无监督学习","slug":"无监督学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"},{"name":"K-Means","slug":"K-Means","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/K-Means/"}],"author":"Justin Bo"},{"title":"机器学习---线性回归:房价预测","slug":"机器学习---线性回归房价预测","date":"2021-02-02T01:37:39.000Z","updated":"2021-03-04T01:25:35.510Z","comments":true,"path":"2021/02/02/7099.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/02/02/7099.html","excerpt":"","text":"机器学习简介小例先来简单举个例子吧！假如一家公司1月的利润为50万，然后每月增长5%，问其9月利润是多少。按照传统算法，我们知道了该公司1月的利润，知道了月增长率，就可以根据公式计算出相应的结果，而机器学习与传统算法不同的是机器学习是把月份、利润这些数据给到计算机，然后由计算机自动去求解一个函数关系进而求得结果。 传统算法：1月利润+公式→计算机→结果 机器学习：前几个月的月份+每月对应的利润→计算机→F（x）（计算机求得的函数关系）→结果 简单定义然后来看看机器学习的一个简单定义吧~ 机器学习是一种实现人工智能的方法从数据中寻找规律、建立关系，然后根据建立的关系去解决问题从数据中学习从而实现自我优化与升级 机器学习的类别1.监督学习：在已有的数据集中，训练数据包括正确结果，知道输入数据与输出结果的关系，并可以根据这种关系建立一个关系模型，在获得新数据后，就可以根据这种关系输出对应结果。 2.无监督学习：训练数据不包括正确结果，让计算机自己去数据中寻找规律。 3.半监督学习：训练数据包含少量结果，可以理解为介于监督学习和无监督学习之间。 4.强化学习：根据每次结果收获的奖惩进行学习，实现优化。就比如让机器人去做一件事，做得好就加5分，做的差就减5分，然后按照第一种方式做事获得的分比第二种方式高，那么机器人就知道第一种方式更好了。按照这种奖惩方式，程序就可以逐步寻找获得高分的方法了。 房屋预测问题实战基于usa_housing_price.csv数据，以人均收入、房屋年龄、房间数量、区域人口、房屋面积作为输入变量，来预测房屋价格。 好了话不多说，上代码！ 这里的csv文件是提前下载好的 #加载数据 import pandas as pd import numpy as np data = pd.read_csv('usa_housing_price.csv') data.head() #预览数据。数据很多，预览数据只是预览前五项。 预览结果： 再来看一下5个输入变量对应的散点图 %matplotlib inline from matplotlib import pyplot as plt #导入相关库 fig = plt.figure(figsize=(15,12)) #这里是定义画布大小 fig1 =plt.subplot(231) #231是指两行三列的第一个图，下面的232是指两行三列的第二个图，依次类推 plt.scatter(data.loc[:,'Avg. Area Income'],data.loc[:,'Price']) #获取数据，画出一个散点图 plt.title('Price VS Income') #散点图的名称 fig2 =plt.subplot(232) plt.scatter(data.loc[:,'Avg. Area House Age'],data.loc[:,'Price']) plt.title('Price VS House Age') fig3 =plt.subplot(233) plt.scatter(data.loc[:,'Avg. Area Number of Rooms'],data.loc[:,'Price']) plt.title('Price VS Number of Rooms') fig4 =plt.subplot(234) plt.scatter(data.loc[:,'Area Population'],data.loc[:,'Price']) plt.title('Price VS Area Population') fig5 =plt.subplot(235) plt.scatter(data.loc[:,'size'],data.loc[:,'Price']) plt.title('Price VS size') plt.show() #展示散点图 注意左上角的1e6是代表10的6次方，即2.5所代表值是2500000。 #定义输入变量X_multi X_multi = data.drop(['Price'],axis=1) #去掉price所在列，因为有5个输入变量，输出结果只有1个，所以去掉price y = data.loc[:,'Price'] X_multi 预览 可以看到这些数据是5000行5列的 from sklearn.linear_model import LinearRegression #导入相关库 LR_multi = LinearRegression()#建立模型 LR_multi.fit(X_multi,y) #训练模型 这里模型已经训练好了： #模型预测 y_predict_multi = LR_multi.predict(X_multi) print(y_predict_multi) 预测结果： #模型评估 from sklearn.metrics import mean_squared_error,r2_score mean_squared_error_multi = mean_squared_error(y,y_predict_multi) r2_score_multi = r2_score(y,y_predict_multi) print(mean_squared_error_multi,r2_score_multi) 评估结果： r2越接近1越好，这里达到0.91，模型还算不错 #图形评估 fig6 = plt.figure(figsize=(9,6)) plt.scatter(y,y_predict_multi) 这里y值和y的预测值接近一条45度的直线，可以看出差别不大 X_test = [66000,3,6,20000,150] X_test = np.array(X_test).reshape(1,-1) #将输入数据转化为数组 print(X_test) y_test_predict = LR_multi.predict(X_test) print(y_test_predict) 自己输入一组数据，可以看到预测结果为114万多一点","categories":[{"name":"人工智能基础","slug":"人工智能基础","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"线性回归","slug":"线性回归","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"}],"author":"Justin Bo"},{"title":"JupyterNotebook的优化与配置","slug":"JupyterNotebook的优化与配置","date":"2021-02-01T14:06:37.000Z","updated":"2021-03-04T02:29:48.953Z","comments":true,"path":"2021/02/01/18760.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/02/01/18760.html","excerpt":"","text":"Jupyter Notebook使用在新建环境中安装Jupyter Notebook 打开Anacanda prompt,键入canda activate envy_name，进入新建环境键入pip install Jupyter Notebook。 建议先将pip升级为最新版本：pip install --upgrade pip。 也可在Anacanda中直接安装不过没有命令行观察直接。Jupyter Notebook的界面优化 安装jupyter-themes包 https://github.com/dunovank/jupyter-themes 在Anacanda prompt中键入使用清华源下载速度会快很多。 pip install --upgrade jupyterthemes -i https://pypi.tuna.tsinghua.edu.cn/simple/ 在安装过程中出现ERROR: Cannot uninstall [pacakage]. It is a distutils installed project…类似错误，就可以先使用pip install --ignore-installed [package]后，再装。也可在E:\\APP\\A\\Lib\\site-packages安装目录下删除所有带有**[pacakage]**的模块。 设置jupyter notebook样式 安装成功后可以先运行 jt -h 查看帮助文档推荐设置的样式代码为 jt -t grade3 -f fira -fs 16 -cellw 90% -ofs 11 -dfs 11 -T 在Jupyter Notebook中显示汉字在绘制散点图时，无法正常显示汉字插入如下两行代码即可解决： plt.rcParams['font.sans-serif'] = ['SimHei'] plt.rcParams['axes.unicode_minus'] = False 若出现以下错误==用来正常显示中文标签显示错误代码plt.rcParams[‘font.sans-serif’] = [‘SimHei’]无法运行==则有以下解决方法： 1. 下载simhei.ttf字体，这里提供一个链接SimHei.ttf 2. 找到你的解释器的fonts文件夹下的ttf文件夹，例如我的解释器是Anaconda，在Anaconda的安装目录下，fonts文件夹的位置如上图的路径：D:\\AnaInstallDir\\Anaconda3\\Lib\\site-packages\\ matplotlib\\mpl-data\\fonts\\ttf。 若解释器是自己安装的Python，文件夹的位置一般为： C:\\Users\\用户名\\AppData\\Local\\Programs\\ Python\\ Python35\\Lib\\site-packages\\matplotlib\\mpl-data\\fonts\\ttf 3. 将下载的SimHei.ttf文件放入ttf文件夹下再运行程序就OK啦（即代码plt.rcParams[‘font.sans-serif’] = [‘SimHei’]可以运行） 参考链接：https://blog.csdn.net/xcjjenifer/article/details/105419979 运行效果如下：","categories":[{"name":"人工智能基础","slug":"人工智能基础","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"},{"name":"工具","slug":"人工智能基础/工具","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Anaconda","slug":"Anaconda","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/Anaconda/"}],"author":"Justin Bo"},{"title":"人工智能与机器学习概念、应用、实现方法","slug":"人工智能与机器学习概念、应用、实现方法","date":"2021-02-01T00:42:01.000Z","updated":"2021-03-04T01:24:16.796Z","comments":true,"path":"2021/02/01/25359.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/02/01/25359.html","excerpt":"","text":"人工智能概念、应用、实现方法生活案例出发：身边的人工智能 人脸识别、自动驾驶、医疗图片诊断 智能机器人、AlphaGo 多语言翻译、智能客服、情感分类 ​ 核心概念人工智能—维基百科定义 人工智能，亦称智机器智能，指由人制造出来的机器所表现出来的智能。 人工智能的核心问题包括建构能够跟人类似甚至超卓的推理、知识、规划、学习、交流、感知、移物、使用工具和操控机械的能力等 人工智能—核心关键词 Intelligence:“The capacity to learn and solve problems ” (自主学习及解决问题的能力) Artificial Intelligence: The simulation of human intelligence by machines (机器对人类智能的模仿) 人工智能—核心定义人工智能就其本质而言，是机器对人的思维或行为过程的模拟，让它能像人一样思考或行动 从过去的信息中寻找规律（经验），将规律或经验吸收，并为未来的判断或决策提供依据。 核心点：学习、优化、决策 部分应用场景 AI安防：利用计算机视觉技术和大数据分析犯罪嫌疑人生活轨迹及可能出现的场所 AI金融：利用复杂的 AI 系统能极其迅速的做出交易决策。 AI工业制造：机器人代替工人在危险场所完成工作 ,在流水线上高效完成重复工作 人工智能发展阶段通用人工智能（“强”人工智能）：具备与人类同等智慧、或超越人类的人工智能，能表现正常人类所具有的所有智能行为。 目前AI技术无法达到通用人工智能 无法判断离通用人工智能还有多远 非通用人工智能（“弱”人工智能）：不需要具有人类完整的认知能力，甚至是完全不具有人类所拥有的感官认知能力 可处理特定问题，在特定应用中很厉害 目前AI处于此阶段 人工智能实现方法：符号人工智能&amp;机器学习（Symbolic Artificial Intelligence &amp; Machine learning)符号学习基于逻辑与规则的学习方法，用一些特定的符号来表示现实的事物或者观念(符号 不局限于图像文字，还包括了既定的逻辑、规则等） ➢ 根据既定的逻辑和顺序告诉机器 接下来做什么 ➢ 遵循if…then…原则 𝑎 = 10, 𝑏 = 20 𝑐 = 𝑎 + 𝑏, 𝑖𝑓 𝑎 &gt; 𝑏； 𝑐 =𝑎 − 𝑏, 𝑖𝑓 𝑎 &lt; 𝑏 𝑐 = ? ? **需要先知道或假设信息的逻辑、规律 ** 机器学习从数据中自动分析获得规律，并利用规律对未知数据进行预测或用于解决实际问题的方法。 ➢从数据中学习规律，实现对原有推 理的更新，实现“自我优化” ➢ 现阶段主流的AI学习算法 只要将数据给机器，机器会自动寻找a b c之间的关系。 机器学习与深度学习的关系机器学习是一种实现人工智能的方法， 深度学习是一种实现机器学习的技术。机器学习：从数据中自动分析获得规律，并利 用规律对未知数据进行预测或用于解决实际问 题的方法。 深度学习：机器在对数据进行分析时，将引入 类人类神经结构模型，实现对复杂数据的理解 与推理，通常可应用于更为复杂的任务中。机器学习概念、应用、实现方法 现实问题思考：营业额预测店铺A第一周营业额为5000，每周增长10%，第10周是多少？ 现实问题思考—自动图像分类目标：以下六组图片，按照自己喜爱的方式分成两组 分组一：站着或非站着 分组二：白色或黄色 分组三：吐舌头或不吐舌头 机器学习应用与概念机器学习是一种实现人工智能的方法。 从数据中寻找规律、建立关系，根据建立的关系去解决问题。 机器学习应用场景 数据挖掘 无人驾驶 机器视觉 语言理解 实现人工智能的主流方法！ 四大学习方法• 监督学习 （Supervised Learning）:在分类过程中，如果所有训练数据都有标签，则为有监督学习，用于分类或者回归。 • 无监督学习（Unsupervised Learning）:如果数据没有标签，显然就是无监督学习了，也即聚类（clustering）。 • 半监督学习 (Semi-supervised Learning) :其训练数据的一部分是有标签的，另一部分没有标签，而没标签数据的数量常常远远大于有标签数据数量（这也是符合现实情况的）。隐藏在半监督学习下的基本规律在于：数据的分布必然不是完全随机的，通过一些有标签数据的局部特征，以及更多没标签数据的整体分布，就可以得到可以接受甚至是非常好的分类结果。 • 强化学习 (Reinforcement Learning) :强化学习是针对你再次没有标注数据集的情况而言的，但你还是有办法来区分是否越来越接近目标（回报函数（reward function））。经典的儿童游戏——“hotter or colder”。（Huckle Buckle Beanstalk的一个变体）是这个概念的一个很好的例证。你的任务是找到一个隐藏的目标物件，然后你的朋友会喊出你是否越来越hotter（更接近）或colder（远离）目标物件。“Hotter/colder”就是回报函数，而算法的目标就是最大化回报函数。你可以把回报函数当做是一种延迟和稀疏的标签数据形式：而不是在每个数据点中获得特定的“right/wrong”答案，你会得到一个延迟的反应，而它只会提示你是否在朝着目标方向前进。 四大学习方法应用场景","categories":[{"name":"人工智能基础","slug":"人工智能基础","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"author":"Justin Bo"},{"title":"在JupyterNotebook中显示汉字","slug":"在JupyterNotebook中显示汉字","date":"2021-01-04T16:04:31.000Z","updated":"2021-03-04T01:28:37.618Z","comments":true,"path":"2021/01/05/34495.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/01/05/34495.html","excerpt":"","text":"在Jupyter Notebook中显示汉字在绘制散点图时，无法正常显示汉字插入如下两行代码即可解决： plt.rcParams['font.sans-serif'] = ['SimHei'] plt.rcParams['axes.unicode_minus'] = False 若出现以下错误==用来正常显示中文标签显示错误代码plt.rcParams[‘font.sans-serif’] = [‘SimHei’]无法运行==则有以下解决方法： 1. 下载simhei.ttf字体，这里提供一个链接SimHei.ttf 2. 找到你的解释器的fonts文件夹下的ttf文件夹，例如我的解释器是Anaconda，在Anaconda的安装目录下，fonts文件夹的位置如上图的路径：D:\\AnaInstallDir\\Anaconda3\\Lib\\site-packages\\ matplotlib\\mpl-data\\fonts\\ttf。 若解释器是自己安装的Python，文件夹的位置一般为： C:\\Users\\用户名\\AppData\\Local\\Programs\\ Python\\ Python35\\Lib\\site-packages\\matplotlib\\mpl-data\\fonts\\ttf 3. 将下载的SimHei.ttf文件放入ttf文件夹下再运行程序就OK啦（即代码plt.rcParams[‘font.sans-serif’] = [‘SimHei’]可以运行） 参考链接：https://blog.csdn.net/xcjjenifer/article/details/105419979 运行效果如下：","categories":[{"name":"人工智能基础","slug":"人工智能基础","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"},{"name":"工具","slug":"人工智能基础/工具","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Anaconda","slug":"Anaconda","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/Anaconda/"}],"author":"Justin Bo"},{"title":"Anaconda的介绍与使用","slug":"Anaconda","date":"2021-01-04T10:18:11.000Z","updated":"2021-03-03T16:09:56.784Z","comments":true,"path":"2021/01/04/41489.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2021/01/04/41489.html","excerpt":"","text":"1.为什么要使用虚拟环境假如当前我们有多个项目A、B、C等等，这些项目中某些项目都需要使用一个相同的库，但是需要的版本却不一样，而这时不管哪个项目使用的都是默认的Python环境，对于这些项目我们只能运行其中一个，如果需要运行另外的项目，必须安装与之相匹配的版本的库。这时我们就可以创建一些完全独立的局部Python环境来实现一个项目使用一个“环境”，这个项目需要安装什么库，只需去其对应的环境中安装即可，这样项目之间就不会互相干扰了，项目的管理也会变得非常方便。 2.conda创建虚拟环境在创建虚拟环境前，需要先下载Anaconda。下载好以后，可以打开命令行输入conda -V检验conda是否安装成功以及当前安装的conda的版本信息。 创建虚拟环境：打开命令行，使用conda create -n env_name python=x.x(这里输入你想要的版本，如3.5、3.6等)命令创建环境名为env_name的虚拟环境。（出现下图所示时输入y即可 创建好虚拟环境以后使用conda activate env_name（创建时的环境名）命令激活虚拟环境（注意:这是Windows下的激活命令）。激活后就可以使用pip install xxx（包名）命令在该虚拟环境下安装你需要的包了。安装好以后，可以使用conda list命令查看已安装的包的信息。若想要退出虚拟环境，输入conda deactivate即可（同样也是Windows下的命令）。存在的虚拟环境可以在Anaconda安装目录里的envs文件下找到，也可以在命令行使用conda env list 或 conda info -e命令查看。 删除虚拟环境及虚拟环境中的某个包删除虚拟环境:conda remove -n env_name --all删除虚拟环境中的某个包:conda remove --name env_name package_name 3.pip换源因为我们获取的包，默认是直接从pypi官网获取的，而pypi是国外的，所以网速很慢，这时我们换成国内镜像源就可以大大提高安装速度了。 这里是几个国内源阿里云 http://mirrors.aliyun.com/pypi/simple/ 中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/ 豆瓣(douban) http://pypi.douban.com/simple/ 清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/ 中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/ 这里以清华源为例。 临时换源:在安装命令后加上-i,指定一个pip源,。eg: pip install scrapy -i https://pypi.tuna.tsinghua.edu.cn/simple 永久换源:win+R 打开用户目录%HOMEPATH%，在此目录下创建 pip 文件夹，在 pip 目录下创建 pip.ini 文件, 内容如下: [global] timeout = 6000 index-url = https://pypi.tuna.tsinghua.edu.cn/simple trusted-host = pypi.tuna.tsinghua.edu.cn","categories":[{"name":"人工智能基础","slug":"人工智能基础","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"},{"name":"工具","slug":"人工智能基础/工具","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Anaconda","slug":"Anaconda","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/Anaconda/"}],"author":"Justin Bo"},{"title":"Qt---信号和槽","slug":"Qt---信号和槽","date":"2020-03-20T01:58:35.000Z","updated":"2021-03-04T02:28:03.558Z","comments":true,"path":"2020/03/20/27139.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2020/03/20/27139.html","excerpt":"","text":"信号与槽（Signal &amp; Slot）：Qt编程的基础，也是 Qt 的一大创新。因为有了信号与槽的编程机制，在 Qt 中处理界面各个组件的交互操作时变得更加直观和简单。 信号（Signal）就是在特定情况下被发射的事件，例如PushButton 最常见的信号就是鼠标单击时发射的 clicked() 信号，一个 ComboBox 最常见的信号是选择的列表项变化时发射的 CurrentIndexChanged() 信号。 GUI 程序设计的主要内容就是对界面上各组件的信号的响应，只需要知道什么情况下发射哪些信号，合理地去响应和处理这些信号就可以了。 槽（Slot）就是对信号响应的函数。槽就是一个函数，与一般的C++函数是一样的，可以定义在类的任何部分（public、private 或 protected），可以具有任何参数，也可以被直接调用。槽函数与一般的函数不同的是：槽函数可以与一个信号关联，当信号被发射时，关联的槽函数被自动执行。 调用实现信号与槽关联是用 QObject::connect() 函数实现的，其基本格式是： QObject::connect(sender, SIGNAL(signal()), receiver, SLOT(slot())); connect() 是 QObject 类的一个静态函数，而 QObject 是所有 Qt 类的基类，在实际调用时可以忽略前面的限定符，所以可以直接写为： connect(sender, SIGNAL(signal()), receiver, SLOT(slot())); 其中，sender 是发射信号的对象的名称，signal() 是信号名称。信号可以看做是特殊的函数，需要带括号，有参数时还需要指明参数。receiver 是接收信号的对象名称，slot() 是槽函数的名称，需要带括号，有参数时还需要指明参数。 SIGNAL 和 SLOT 是 Qt 的宏，用于指明信号和槽，并将它们的参数转换为相应的字符串。例如，如下的语句： QObject::connect(btnClose, SIGNAL(clicked()), Widget, SLOT(close())); 其作用就是将 btnClose 按钮的 clicked() 信号与窗体（Widget）的槽函数 close() 相关联，这样，当单击 btnClose 按钮（就是界面上的“Close”按钮）时，就会执行 Widget 的 close() 槽函数。 注意事项 关于信号与槽的使用，有以下一些规则需要注意： 一个信号可以连接多个槽，例如： connect(spinNum, SIGNAL(valueChanged(int)), this, SLOT(addFun(int)); connect(spinNum, SIGNAL(valueChanged(int)), this, SLOT(updateStatus(int)); 这是当一个对象 spinNum 的数值发生变化时，所在窗体有两个槽进行响应，一个 addFun()**用于计算，一个 **updateStatus() 用于更新状态。 当一个信号与多个槽函数关联时，槽函数按照建立连接时的顺序依次执行。 当信号和槽函数带有参数时，在 connect()函数里，要写明参数的类型，但可以不写参数名称。 多个信号可以连接同一个槽，例如让三个选择颜色的 RadioButton的clicked() 信号关联到相同的一个自定义槽函数 **setTextFontColor()**。 connect(ui->rBtnBlue,SIGNAL(clicked()),this,SLOT(setTextFontColor())); connect(ui->rBtnRed,SIGNAL(clicked()),this,SLOT(setTextFontColor())); connect(ui->rBtnBlack,SIGNAL(clicked()),this,SLOT(setTextFontColor())); 这样，当任何一个 RadioButton 被单击时，都会执行 setTextFontColor() 函数。 一个信号可以连接另外一个信号，例如： connect(spinNum, SIGNAL(valueChanged(int)), this, SIGNAL (refreshInfo(int)); 这样，当一个信号发射时，也会发射另外一个信号，实现某些特殊的功能。 严格的情况下，信号与槽的参数个数和类型需要一致，至少信号的参数不能少于槽的参数。如果不匹配，会出现编译错误或运行错误。 在使用信号与槽的类中，必须在类的定义中加入宏 Q_OBJECT。 当一个信号被发射时，与其关联的槽函数通常被立即执行，就像正常调用一个函数一样。只有当信号关联的所有槽函数执行完毕后，才会执行发射信号处后面的代码。 信号与槽机制是 Qt GUI 编程的基础，使用信号与槽机制可以比较容易地将信号与响应代码关联起来。","categories":[{"name":"Qt学习笔记","slug":"Qt学习笔记","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/Qt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"工具","slug":"工具","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E5%B7%A5%E5%85%B7/"},{"name":"GUI","slug":"GUI","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/GUI/"}],"author":"Justin Bo"},{"title":"初识Qt","slug":"初识Qt","date":"2020-03-20T01:58:35.000Z","updated":"2021-03-04T02:30:14.033Z","comments":true,"path":"2020/03/20/28487.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2020/03/20/28487.html","excerpt":"","text":"1.什么是QtQt是一个跨平台的C++**图形用户界面（GUI**）应用程序框架。 2.创建一个新Qt窗口文件2.1第一步 按如上选择，生成一个带Qt Widget 的APP 2.2第二步 路径不能有中文，否则构筑条飘红且没反应，但不会报错！！！ 2.3第三步 相当于选择编译器 QMainWindow、QWidget、QDialog都是基类。QMainWindow是一个带菜单栏的窗口，主要用在Windows下；QWidget是Qt窗口类的一个基类，空白窗口，所有按钮标签都继承于此基类；QDialog是一个对话框（不能伸缩）。 类名MyWidget是QWidget的子类，Qt会生成名为mywidget.h的头文件和mywidget.c的文件。mywidget.h文件中会有一行代码： class MyWidget:public QWidget 代表MyWidget继承自父类QWidget 创建界面是用来图形化设计界面，第一天用不到。 2.5完成最后Qt工程会生成以下文件： 软件左下角为编译等按钮： 最上为项目，生成可执行文件类型的选择；第二个为编译且运行；第三个为编译并调试；第四个为编译不运行。运行完会生成一个空白窗口。按下以上按钮会在同级目录下生成一个文件夹，里面有不同类型的可执行文件，以build开头： 3. 生成的新Qt窗口文件3.1 main.cpp为主函数，它的内容为：#include \"mywidget.h\" //QApplication应用程序类 //Qt头文件没有.h //头文件和类名一样 #include int main(int argc, char *argv[]) &#123; //有且只有一个应用程序类的对象a QApplication a(argc, argv); //MyWidget继承于QWidget ，QWidget是一个窗口基类 //MyWidget也是窗口类 //w就是一个窗口 MyWidget w; //窗口默认隐藏，需要人为调用show显示 w.show(); //让程序一直执行，等待用户操作 //等待事件的发生 a.exec(); return 0; &#125; 3.2mywidget.h为mywidget窗口类文件，内容为：#ifndef MYWIDGET_H #define MYWIDGET_H #include class MyWidget : public QWidget &#123; //信号与槽的时候需要 Q_OBJECT public: MyWidget(QWidget *parent = 0); ~MyWidget(); &#125;; #endif // MYWIDGET_H 3.3 Qt_test.pro为项目文件，内容为：#模块 QT += core gui #高于QT4版本添加 QT += widgets，为了兼容Qt4 greaterThan(QT_MAJOR_VERSION, 4): QT += widgets #应用程序的名字 TARGET = Qt1_test #指定makefile的类型，app TEMPLATE = app DEFINES += QT_DEPRECATED_WARNINGS CONFIG += c++11 #源文件 .cpp文件 SOURCES += \\ main.cpp \\ mywidget.cpp \\ subwidget.cpp #头文件 .h文件 HEADERS += \\ mywidget.h \\ subwidget.h # Default rules for deployment. qnx: target.path = /tmp/$$&#123;TARGET&#125;/bin else: unix:!android: target.path = /opt/$$&#123;TARGET&#125;/bin !isEmpty(target.path): INSTALLS += target 需要时，在此导入新的模块，类似于python的import。","categories":[{"name":"Qt学习笔记","slug":"Qt学习笔记","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/Qt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"工具","slug":"工具","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E5%B7%A5%E5%85%B7/"},{"name":"GUI","slug":"GUI","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/GUI/"}],"author":"Justin Bo"},{"title":"数据库三范式","slug":"数据库三范式","date":"2020-03-02T03:45:00.000Z","updated":"2021-03-04T02:28:22.421Z","comments":true,"path":"2020/03/02/15177.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2020/03/02/15177.html","excerpt":"","text":"参考 https://blog.csdn.net/dh2442897094/article/details/105656952https://blog.csdn.net/qq_42351920/article/details/81303550 数据库设计三大范式为了建立冗余较小、结构合理的数据库，设计数据库时必须遵循一定的规则。在关系型数据库中这种规则就称为范式。范式是符合某一种设计要求的总结。要想设计一个结构合理的关系型数据库，必须满足一定的范式。 第一范式(确保每列保持原子性)； 第二范式(确保表中的每列都和主键相关)； 第三范式(确保每列都和主键列直接相关,而不是间接相关)； 在实际开发中最为常见的设计范式有三个： 第一范式（1NF）：要求数据库表的每一列都是不可分割的原子数据项。第一范式是最基本的范式。如果数据库表中的所有字段值都是不可分解的原子值，就说明该数据库表满足了第一范式。 第一范式的合理遵循需要根据系统的实际需求来定。比如某些数据库系统中需要用到“地址”这个属性，本来直接将“地址”属性设计成一个数据库表的字段就行。但是如果系统经常会访问“地址”属性中的“城市”部分，那么就非要将“地址”这个属性重新拆分为省份、城市、详细地址等多个部分进行存储，这样在对地址中某一部分操作的时候将非常方便。这样设计才算满足了数据库的第一范式，如下表所示。举例说明：在上面的表中，“家庭信息”和“学校信息”列均不满足原子性的要求，故不满足第一范式，调整如下：可见，调整后的每一列都是不可再分的，因此满足第一范式（1NF）； 第二范式（2NF）： 第二范式需要确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。 在1NF的基础上，非码属性必须完全依赖于候选码（在1NF基础上消除非主属性对主码的部分函数依赖）。也就是说在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。举例说明：在上图所示的情况中，同一个订单中可能包含不同的产品，因此主键必须是“订单号”和“产品号”联合组成，但可以发现，产品数量、产品折扣、产品价格与“订单号”和“产品号”都相关，但是订单金额和订单时间仅与“订单号”相关，与“产品号”无关，这样就不满足第二范式的要求，调整如下，需分成两个表： 第三范式（3NF）： 第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。 在2NF基础上，任何非主属性不依赖于其它非主属性（在2NF基础上消除传递依赖） 举例说明： 上表中，所有属性都完全依赖于学号，所以满足第二范式，但是“班主任性别”和“班主任年龄”直接依赖的是“班主任姓名”， 而不是主键“学号”，所以需做如下调整： 这样以来，就满足了第三范式的要求。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"author":"Justin Bo"},{"title":"如何用Hexo优雅的书写文章","slug":"写文章","date":"2020-01-03T00:09:10.000Z","updated":"2021-03-03T16:11:30.972Z","comments":true,"path":"2020/01/03/62216.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2020/01/03/62216.html","excerpt":"","text":"了解文章目录所有的文章都是放在主目录下source文件下的_posts目录下的，这里参考我的存放目录E:\\mblog\\source\\_posts 这里作出两点说明： 该目录下可以再创建目录，系统可以识别到多层文件夹中的文章，方便分类 如果用命令生成的新文章一定是在_posts主目录下 熟悉操作指令其实就是一句话，再把生成的文章拖到_posts目录下你自己创建的文件夹即可，文件后缀为.md hexo n 你的文章名 Tips： 如果嫌麻烦，复制md文件再粘贴也是个好办法 开始书写文章写MarkDown这里推荐Typora，非常好用，点开创建的文件，先看看里面有啥\\---title: typora-vue-theme主题介绍date: 2018-09-07 09:25:00\\--- 两个虚线之间的内容就是叫Front-matter，主要是你文章的配置，具体配置如下，这里不同主题不一样，我以Matery主题为例 Front-matter 选项中的所有内容均为非必填的。但我仍然建议至少填写 title 和 date 的值。 配置选项 默认值 描述 title Markdown 的文件标题 文章标题，强烈建议填写此选项 date 文件创建时的日期时间 发布时间，强烈建议填写此选项，且最好保证全局唯一 author 根 _config.yml 中的 author 文章作者 img featureImages 中的某个值 文章特征图，推荐使用图床(腾讯云、七牛云、又拍云等)来做图片的路径.如: http://xxx.com/xxx.jpg top true 推荐文章（文章是否置顶），如果 top 值为 true，则会作为首页推荐文章 cover false v1.0.2版本新增，表示该文章是否需要加入到首页轮播封面中 coverImg 无 v1.0.2版本新增，表示该文章在首页轮播封面需要显示的图片路径，如果没有，则默认使用文章的特色图片 password 无 文章阅读密码，如果要对文章设置阅读验证密码的话，就可以设置 password 的值，该值必须是用 SHA256 加密后的密码，防止被他人识破。前提是在主题的 config.yml 中激活了 verifyPassword 选项 toc true 是否开启 TOC，可以针对某篇文章单独关闭 TOC 的功能。前提是在主题的 config.yml 中激活了 toc 选项 mathjax false 是否开启数学公式支持 ，本文章是否开启 mathjax，且需要在主题的 _config.yml 文件中也需要开启才行 summary 无 文章摘要，自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要 categories 无 文章分类，本主题的分类表示宏观上大的分类，只建议一篇文章一个分类 tags 无 文章标签，一篇文章可以多个标签 keywords 文章标题 文章关键字，SEO 时需要 reprintPolicy cc_by 文章转载规则， 可以是 cc_by, cc_by_nd, cc_by_sa, cc_by_nc, cc_by_nc_nd, cc_by_nc_sa, cc0, noreprint 或 pay 中的一个 注意: 1.如果 img 属性不填写的话，文章特色图会根据文章标题的 hashcode 的值取余，然后选取主题中对应的特色图片，从而达到让所有文章都的特色图各有特色。 2.date 的值尽量保证每篇文章是唯一的，因为本主题中 Gitalk 和 Gitment 识别 id 是通过 date 的值来作为唯一标识的。 3.如果要对文章设置阅读验证密码的功能，不仅要在 Front-matter 中设置采用了 SHA256 加密的 password 的值，还需要在主题的 _config.yml 中激活了配置。有些在线的 SHA256 加密的地址，可供你使用：开源中国在线工具、chahuo、站长工具。 4.您可以在文章md文件的 front-matter 中指定 reprintPolicy 来给单个文章配置转载规则 以下为文章的 Front-matter 示例。 最全示例 title: typora-vue-theme主题介绍 date: 2018-09-07 09:25:00 author: 赵奇 img: /source/images/xxx.jpg top: true cover: true coverImg: /images/1.jpg password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92 toc: false mathjax: false summary: 这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要 categories: Markdown tags: - Typora - Markdown Tips：你会发现一个问题，每次hexo n的时候Front-matter中内容少的可怜，那怎么修改默认的格式呢？只要去主目录下找到scaffolds文件夹下找到一个post.md文件修改即可 首行缩进方法 由于markdowm会自动限定格式，所以缩进显得比较困难，通常我们使用Tab按键或者打空格实现的缩进都只能缩进一小部分，这时可以通过占位符实现更多的缩进效果，使得文章变得美观 一个汉字占两个空格大小，所以使用四个空格就可以达到首行缩进两个汉字的效果。有如下几种方法： 一个空格大小的表示： 或 ，此时只要在相应需要缩进的段落前加上 4个 如上的标记即可，注意要带上分号 两个空格的大小表示： 或 ，同理，使用2个即可缩进2个汉字，推荐使用该方式。 不换行空格： 或 ，使用4个 即可。 范例不使用任何缩进效果 使用Tab实现缩进 在前面打上很多空格实现缩进 使用4个 &amp;#160 实现缩进 使用2个 &amp;emsp 实现缩进 使用 4个&amp;ensp 实现缩进","categories":[{"name":"博客","slug":"博客","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"工具","slug":"工具","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E5%B7%A5%E5%85%B7/"},{"name":"hexo","slug":"hexo","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/hexo/"}],"author":"JustinBo"},{"title":"hexo搭建博客步骤","slug":"博客搭建","date":"2020-01-01T03:19:08.000Z","updated":"2021-03-03T16:11:44.512Z","comments":true,"path":"2020/01/01/63100.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2020/01/01/63100.html","excerpt":"","text":"hexo简介hexo 自称为：快速、简洁且高效的博客框架。 笔者用起来确实还可以，大概介绍下几个特性： 提供了不同的layout，可将文章存为草稿，需要时publish即可； 可维护全局的数据，在source/_data文件夹下添加yaml文件，通过site.data获取； 可指定文件的特有变量，通过Front-matter实现； 支持模板，在scaffolds文件夹下可自定义模板，并进行发布； 支持标签插件，可以在文章文件中使用标签%%来插入特定内容； 提供命令行操作，如：hexo init初始化项目、hexo new新建文章、hexo pulish发布草稿文件、hexo generate生成静态文件、hexo server启动服务器； hexo搭建博客步骤 前提是必须安装好git和nodejs； 执行 “npm install -g hexo-cli”，安装好hexo； 选定文件夹，通过 “hexo init $folder” 初始化一个名为 $folder 的文件夹； cd $folder, 再执行npm install，至此hexo的博客框架已经搭建完成！ 完成上述步骤后，可执行hexo server, 访问http://localhost:4000, 会发现一个HelloWorld页面已经可以访问！ 选用volantis主题 设置项目使用的主题: 项目根目录下的_config.yml文件中设置 theme: volantis; 如果Hexo版本在5.0.2及以上，可以直接通过npm i hexo-theme-volantis进行安装；笔者为了项目的可读性，采用了源代码拷贝到theme文件夹的方案（记得删除.git文件夹,否则git提交时会出问题!） 按照依赖的插件：npm i hexo-generator-search hexo-generator-json-content(站内搜索)，npm i hexo-renderer-stylus（Stylus 渲染器） 完成上述步骤后执行hexo server, 访问http://localhost:4000, 是不是发现端庄不失典雅的博客网站已经完成了！ 尝试新建文章执行 hexo new post $newPostName，会在_post文件夹下新建一个名为$newPostName的md文件，一个新的文章便建立完成。 这时你只需要关注你的博文输出即可啦！ 发布至GitHub Pages如果你期望能通过GitHub Pages来访问你的博客网站，做如下几步： 通过GitHub新建一个repository，名为：&lt;你的 GitHub 用户名&gt;.github.io； 本地检出该repository； 在博客源码的项目中执行命令：hexo generate –deploy，会生成public文件夹，该文件夹里便是博客所有的静态页面文件； 将public文件夹中的文件全部拷贝到新建repository的master分支下； 将master文件推送至远程master分支即可！ 静待一会，访问：http://&lt;你的 GitHub 用户名&gt;.github.io便能访问你自定义的博客了！ 如果你有自己的域名，可以在域名解析配置成 记录类型：CNAME，记录值：&lt;你的 GitHub 用户名&gt;.github.io。 注意了！！！ 此时还需要在GitHub Page项目中根目录下加上名为CNAME的文件，文件内容为你自己的域名。 正如你看到的，搭建一个个人博客网站就是如此便捷！","categories":[{"name":"博客","slug":"博客","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"工具","slug":"工具","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E5%B7%A5%E5%85%B7/"},{"name":"hexo","slug":"hexo","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/hexo/"}],"author":"Justin Bo"},{"title":"花津南路(完....)","slug":"花津南路","date":"2019-05-31T10:21:19.000Z","updated":"2021-03-03T01:14:13.621Z","comments":true,"path":"2019/05/31/7103.html","link":"","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/2019/05/31/7103.html","excerpt":"","text":"序 不知道什么时候的事情了, 对拍好看的照片总是有点向往 有台相机还是蛮好的 , 有空的时候也有动力跑出去瞎拍一通 不是配置狗 , 相机 Sony Nex 5T , 16-50 mm ,f3.5-5.6 , 七工匠 25mm f1.8 后期用的是LightRoom (瞎调) 2019-06-11 镜湖 中江桥 噪点奇多 看来是时候入手一个大光圈镜头了 Others 2019-06-16 学校的荷花 2019-06-21 八佰伴附近 AHNU赭山校区 夜晚的镜湖 2019-06-26 滨江公园 长江二桥 长江江景 世茂滨江 天主教堂 Others","categories":[{"name":"旅行志","slug":"旅行志","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E6%97%85%E8%A1%8C%E5%BF%97/"}],"tags":[{"name":"旅行","slug":"旅行","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%97%85%E8%A1%8C/"},{"name":"摄影","slug":"摄影","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%91%84%E5%BD%B1/"}],"author":"Justin Bo"}],"categories":[{"name":"面试常见问题","slug":"面试常见问题","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E9%9D%A2%E8%AF%95%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"name":"人工智能基础","slug":"人工智能基础","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"},{"name":"工具","slug":"人工智能基础/工具","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/%E5%B7%A5%E5%85%B7/"},{"name":"Qt学习笔记","slug":"Qt学习笔记","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/Qt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"数据库","slug":"数据库","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"博客","slug":"博客","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E5%8D%9A%E5%AE%A2/"},{"name":"旅行志","slug":"旅行志","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/categories/%E6%97%85%E8%A1%8C%E5%BF%97/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E7%BD%91%E7%BB%9C/"},{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"深度学习","slug":"深度学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"CNN","slug":"CNN","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/CNN/"},{"name":"多层感知机","slug":"多层感知机","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"name":"逻辑回归","slug":"逻辑回归","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"},{"name":"无监督学习","slug":"无监督学习","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"},{"name":"K-Means","slug":"K-Means","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/K-Means/"},{"name":"线性回归","slug":"线性回归","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},{"name":"Anaconda","slug":"Anaconda","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/Anaconda/"},{"name":"工具","slug":"工具","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E5%B7%A5%E5%85%B7/"},{"name":"GUI","slug":"GUI","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/GUI/"},{"name":"数据库","slug":"数据库","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"hexo","slug":"hexo","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/hexo/"},{"name":"旅行","slug":"旅行","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%97%85%E8%A1%8C/"},{"name":"摄影","slug":"摄影","permalink":"https://github.com/JustinLibo/JustinLibo.github.io.git/tags/%E6%91%84%E5%BD%B1/"}]}